{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/mas1004/blob/2024/assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyoaVyiFO4h_"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "In this assignment, you will practice with defining class and handling torch tensors\n",
        "\n",
        "- Submission\n",
        "  1. Complete the code in this notebook.\n",
        "  2. Download `assignment_1.py` file using the code in the last cell.\n",
        "  3. Copy and paste the code you implemented in the notebook to the `assignment_1.py` file.\n",
        "  4. Submit BOTH ipynb and py file to the Cyber Campus.\n",
        "    - File name has to be in the following format: ``assignment_1_{your_student_number}.ipynb/py``\n",
        "    - For example: ``assignment_1_20201234.ipynb``, ``assignment_1_20201234.py``\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ubQ6aVkO4iA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from math import sin, cos, exp\n",
        "from typing import List, Tuple, Union\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRBPJJGiO4iB"
      },
      "source": [
        "## Problem 1-1. Practice with Class\n",
        "- Complete ``MyFunction`` class\n",
        "  - ``MyFunction`` class is instantiated with ``params``, a list of parameters\n",
        "    - ``params`` is a list of float values\n",
        "    - Let's name items in `params` in alphabet so that ``params`` = $[a, b, c, d, e]$\n",
        "  - ``MyFunction`` class has ``__call__`` method\n",
        "    - it takes a float value ``x`` as an input and return $f(x)$\n",
        "    - $f(x) = ax + b\\cos(x) + c\\sin(x) + dx^2 + e  $\n",
        "  - ``MyFunction`` class has ``__len__`` method\n",
        "    - it returns the number of non-zero parameters\n",
        "    - For example, if $a=0$, $b=3$, $c=0$, $d=3$, $e=0$, then ``__len__`` method returns 2\n",
        "  - ``MyFunction`` class has ``__add__`` method\n",
        "    - it takes another ``MyFunction`` class instance ``other`` as an input and return a new ``MyFunction`` class instance\n",
        "    - the new ``MyFunction`` class instance has parameters $[a+a', b+b', c+c', d+d', e+e']$, where $a', b', c', d', e'$ are parameters of ``other`` instance\n",
        "  - ``MyFunction`` class has ``calculate_list_input`` method\n",
        "    - it takes a list of float values ``x_list`` as an input and return a list of $f(x)$ values\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZEmMA4pO4iB"
      },
      "outputs": [],
      "source": [
        "class MyFunction:\n",
        "  def __init__(self, params: List[float]) -> None:\n",
        "    '''\n",
        "    The instance is initialized with a list of parameters.\n",
        "    The parameters are in the following order:\n",
        "    [a, b, c, d, e]\n",
        "    where the function is:\n",
        "    $f(x) =  ax + b\\cos(x) + c\\sin(x) + dx^2 + e $\n",
        "    '''\n",
        "    self.params = params\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    '''\n",
        "    return the number of NON-ZERO parameters.\n",
        "    For example, if the parameters are [1, 0, 3, 0, 5], then the length is 3, ignoring the two zeros.\n",
        "\n",
        "    TODO: implement this\n",
        "    '''\n",
        "    return\n",
        "\n",
        "  def __add__(self, other: 'MyFunction') -> 'MyFunction':\n",
        "    '''\n",
        "    This function adds two MyFunction objects together.\n",
        "    It returns a new MyFunction object with the sum of the parameters.\n",
        "    It is called when you do something like:\n",
        "    >>> f1 = MyFunction([1, 2, 3])\n",
        "    >>> f2 = MyFunction([4, 5, 6])\n",
        "    >>> f3 = f1 + f2\n",
        "    >>> print(f3.params)\n",
        "    [5, 7, 9]\n",
        "\n",
        "    TODO: implement this\n",
        "    '''\n",
        "    return\n",
        "\n",
        "  def __call__(self, x:float) -> float:\n",
        "    '''\n",
        "    return the function value at x\n",
        "    $f(x) =  ax + b\\cos(x) + c\\sin(x) + dx^2 + e $\n",
        "\n",
        "    TODO: implement this\n",
        "    '''\n",
        "    return\n",
        "\n",
        "  def calculate_list_input(self, x: List[float]) -> List[float]:\n",
        "    '''\n",
        "    args:\n",
        "      x: a list of floats\n",
        "    return:\n",
        "      a list of function values at x\n",
        "\n",
        "    TODO: implement this using __call__\n",
        "    HINT: you can use self(float_value) to call __call__\n",
        "    '''\n",
        "    return\n",
        "\n",
        "\n",
        "my_function = MyFunction([1, 0, 3, 0, 5])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kRKDuudO4iB"
      },
      "outputs": [],
      "source": [
        "# Test cases for MyFunction\n",
        "\n",
        "my_function = MyFunction([1, 0, 3, 0, 5])\n",
        "test_input = [-1, 0, 3]\n",
        "\n",
        "assert len(my_function) == 3, 'your __len__ implementation is wrong'\n",
        "assert len(MyFunction([0, 0, 0, 0, 0])) == 0, 'your __len__ implementation is wrong'\n",
        "assert len(MyFunction([2, 3, 2, -2, -2])) == 5, 'your __len__ implementation is wrong'\n",
        "\n",
        "assert my_function(0) == 5, 'your __call__ implementation is wrong'\n",
        "assert my_function(-1) == 1.4755870455763107, 'your __call__ implementation is wrong'\n",
        "\n",
        "function_1 = MyFunction([1, 0, 3, 0, 5])\n",
        "function_2 = MyFunction([-2, 1, 0, -1, 2])\n",
        "\n",
        "function_3 = function_1 + function_2\n",
        "assert isinstance(function_3, MyFunction), 'MyFunction.__add__ has to return a MyFunction object'\n",
        "assert function_3.params == [-1, 1, 3, -1, 7], 'your __add__ implementation is wrong'\n",
        "\n",
        "test_output = function_1.calculate_list_input(test_input)\n",
        "assert test_output == [1.4755870455763107, 5.0, 8.423360024179601], 'your calculate_list_input implementation is wrong'\n",
        "\n",
        "print('All tests passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDYNHC7YO4iC"
      },
      "source": [
        "## Problem 1-2: Instantiation of ``MyFunction`` class\n",
        "- Instantiate ``MyFunction`` class so that you can get following functions\n",
        "   - $f_a(x) = 2x + 1$\n",
        "   - $f_b(x) = 3x + 2\\cos(x) + 1\\sin(x) - 0.5 * x^2 + 5$\n",
        "   - $f_c(x) = 3\\cos(x) + 2\\sin(x)$\n",
        "- You can implement it by using ``MyFunction`` class and and proper ``params`` list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlPjd3UuO4iC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def answer_for_problem2()-> Tuple[MyFunction, MyFunction, MyFunction]:\n",
        "  '''\n",
        "  args:\n",
        "    None\n",
        "\n",
        "  returns:\n",
        "    function_a: MyFunction\n",
        "    function_b: MyFunction\n",
        "    function_c: MyFunction\n",
        "  '''\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "func_a, func_b, func_c = answer_for_problem2()\n",
        "\n",
        "assert isinstance(func_a, MyFunction) and isinstance(func_b, MyFunction) and isinstance(func_c, MyFunction), \"Please return three MyFunction objects\"\n",
        "\n",
        "\n",
        "x_examples = [(i-100)/20 for i in range(201)]\n",
        "\n",
        "y_a = func_a.calculate_list_input(x_examples)\n",
        "y_b = func_b.calculate_list_input(x_examples)\n",
        "y_c = func_c.calculate_list_input(x_examples)\n",
        "\n",
        "assert torch.allclose(torch.tensor(y_a[10:15]), torch.tensor([-8.0, -7.9, -7.8, -7.7, -7.6]), atol=1e-6), \"Function a is not correct\"\n",
        "assert torch.allclose(torch.tensor(y_b[10:15]), torch.tensor([-18.0691, -17.8043, -17.5431, -17.2852, -17.0304]), atol=1e-4), \"Function a is not correct\"\n",
        "assert torch.allclose(torch.tensor(y_c[10:15]), torch.tensor([1.3227, 1.1534, 0.9812, 0.8066, 0.6299]), atol=1e-4), \"Function a is not correct\"\n",
        "\n",
        "print(\"Test case passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXM_lBwGO4iC"
      },
      "source": [
        "### Problem 1-2: Plot $f_a(x)$, $f_b(x)$, and $f_c(x)$\n",
        "If you implement it correctly, you will get following figure\n",
        "\n",
        "![img](https://github.com/jdasam/mas1004/blob/2023/assignment1_fig1.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Woz4AcipO4iC"
      },
      "outputs": [],
      "source": [
        "plt.xticks(range(0, 201, 20), x_examples[::20])\n",
        "plt.plot(y_a, label='f_a')\n",
        "plt.plot(y_b, label='f_b')\n",
        "plt.plot(y_c, label='f_c')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV0yx54tO4iC"
      },
      "source": [
        "### Problem 1-3: Class inheritance\n",
        "- Complete ``AnotherFunction`` class\n",
        "  - ``AnotherFunction`` class inherits ``MyFunction`` class\n",
        "    - If you *inherit* a class, you can use all methods in the parent class\n",
        "      - You can inherit a class by writing ``class ChildClass(ParentClass):``\n",
        "    - Then, you can override methods in the parent class\n",
        "      - You can override a method by writing ``def method_name(self, ...):``\n",
        "      - If you override a method in the child class, the method in the parent class is not used\n",
        "  - ``AnotherFunction`` class has ``__call__`` method\n",
        "    - it takes a float value ``x`` as an input and return $f(x)$\n",
        "    - $f(x) = ax + bx^3 + c\\times2^x + d\\times3^x + e \\times \\exp(x)$\n",
        "      - note that `e` in `e \\times \\exp(x)` is a parameter of the function, NOT the Euler's number (2.71828...)\n",
        "    - $\\exp(x)$, or $e^x$ with Eueler's number $e$, can be computed by ``math.exp(x)``\n",
        "      - or `exp(x)` if you write ``from math import exp``\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHlqkqjEO4iC"
      },
      "outputs": [],
      "source": [
        "# Class Inheritance Example\n",
        "# You don't need to implement anything here.\n",
        "\n",
        "class ChildClass(MyFunction):\n",
        "  def __init__(self, params: List[float]) -> None:\n",
        "    super().__init__(params)\n",
        "    #MyFunction.__init__(self, params)\n",
        "\n",
        "child_function = ChildClass([1, 2, 0, 4, 1])\n",
        "\n",
        "# Every method in MyFunction is also available in ChildClass\n",
        "print(f\"__len__ of child_function: {len(child_function)}\")\n",
        "print(f\"__call__(1) of child_function: {child_function(1)}\")\n",
        "print(f\"calculate_list_input of child_function: {child_function.calculate_list_input([1, 2, 3])}\")\n",
        "\n",
        "# instance of ChildClass is also an instance of MyFunction\n",
        "print(f\"Is child_function an instance of MyFunction? {isinstance(child_function, MyFunction)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIUwc8fMO4iC"
      },
      "outputs": [],
      "source": [
        "# Problem starts here!\n",
        "\n",
        "class AnotherFunction(MyFunction):\n",
        "  def __init__(self, params: List[float]) -> None:\n",
        "    super().__init__(params)\n",
        "\n",
        "  def __call__(self, x:float) -> float:\n",
        "    '''\n",
        "    args:\n",
        "      x: a float value\n",
        "    return:\n",
        "      a float value\n",
        "      $f(x) = ax + bx^3 + c\\times2^x + d\\times3^x + e \\times \\exp(x)$\n",
        "\n",
        "    TODO: implement this\n",
        "    '''\n",
        "    return\n",
        "\n",
        "another_func = AnotherFunction([3, 0.1, -0.01, -0.01, 0.02])\n",
        "print(f\"Parameters of another function are {another_func.params}\")\n",
        "\n",
        "# You do not have to implement calculate_list_input() again. It is inherited from MyFunction\n",
        "y_another = another_func.calculate_list_input(x_examples)\n",
        "plt.xticks(range(0, 201, 20), x_examples[::20])\n",
        "plt.plot(y_another, label='f_another')\n",
        "\n",
        "assert torch.allclose(torch.tensor(y_another[30:35]), torch.tensor([-14.7880, -14.4569, -14.1309, -13.8101, -13.4942]), atol=3e-4), \"Your implementation of AnotherFunction is not correct\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxHRcvyLO4iC"
      },
      "source": [
        "## Problem 2: Implementing Matrix Multiplication\n",
        "$\n",
        "\\left[\\begin{array}{cc}\n",
        "1 & 2 & 3\\\\\n",
        "4 & 5 & 6\n",
        "\\end{array}\\right]\n",
        "\\times\n",
        "\\left[\\begin{array}{cc}\n",
        "1 & 2\\\\\n",
        "3 & 4 \\\\\n",
        "5 & 6 \\\\\n",
        "\\end{array}\\right] =\n",
        "$\n",
        "\n",
        "- In this problem, you have to implement matrix multiplication with for loops and multiplication, addition operators\n",
        "  - You cannot use ``numpy``, ``torch`` or  other matrix multiplication functions\n",
        "  \n",
        "- You have to implement condition checkings\n",
        "  - If the input matrices are not compatible for multiplication, you have to raise an error\n",
        "    - For example, if you multiply $2\\times3$ matrix with $2\\times2$ matrix, you have to raise an error\n",
        "  - If the input matrices are compatible for multiplication, you have to return the result matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zlz9fyQuO4iD"
      },
      "outputs": [],
      "source": [
        "def matrix_multiply_using_for_loop(mat_a: List[List[float]], mat_b: List[List[float]]) -> list:\n",
        "  '''\n",
        "  args:\n",
        "    mat_a: List of list of float (or integer), has shape m x n. If not a matrix, return 'Error'\n",
        "    mat_b: List of list of float (or integer), has shape n x p. If not a matrix, return 'Error'\n",
        "  return:\n",
        "    an m x p matrix in list of list format\n",
        "\n",
        "  TODO: implement this function using for loop and check_condition()\n",
        "  '''\n",
        "  def check_condition():\n",
        "    '''\n",
        "    This is inner function. You do not need to get arguments from outside.\n",
        "    In other words, variables defined outside of this function is available inside this function.\n",
        "    For example, you can refer to mat_a and mat_b inside this function, without passing them as arguments.\n",
        "\n",
        "    args:\n",
        "      None\n",
        "    return:\n",
        "      True if the mat_a and mat_b can be represented as a matrix and can be multiplied, False otherwise.\n",
        "    '''\n",
        "\n",
        "    # TODO: implement this function\n",
        "    return\n",
        "\n",
        "  condition = check_condition()\n",
        "  if condition is False:\n",
        "    return 'Error'\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "matrix_a = [[1, 2, 3], [4, 5, 6]]\n",
        "matrix_b = [[1, 2], [3, 4], [5, 6]]\n",
        "\n",
        "result = matrix_multiply_using_for_loop(matrix_a, matrix_b)\n",
        "print(f\"Result of matrix multiplication using for loop: {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTFCHSxHO4iD"
      },
      "outputs": [],
      "source": [
        "test_a = [[1, 2, 3], [4, 5]]\n",
        "test_b = [[1, 2], [3, 4], [5, 6]]\n",
        "test_c = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "\n",
        "result_a = matrix_multiply_using_for_loop(test_a, test_b)\n",
        "result_b = matrix_multiply_using_for_loop(test_b, test_c)\n",
        "result_c = matrix_multiply_using_for_loop(test_c, test_b)\n",
        "\n",
        "assert result_a == 'Error', f\"result_a should be 'Error', but got {result_a}\"\n",
        "assert result_b == 'Error', f\"result_b should be 'Error', but got {result_b}\"\n",
        "assert result_c == [[22, 28], [49, 64], [76, 100]], f\"result_c should be [[22, 28], [49, 64], [76, 100]], but got {result_c}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9j93V_oO4iD"
      },
      "source": [
        "## Problem 3: Tensor Handling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxI1sK86O4iD"
      },
      "source": [
        "### 3-1. Implementing Tensor Addition\n",
        "- Complete simple adding function of two tensors\n",
        "- Complete correct ``condition`` so that you don't get error\n",
        "  - ``condition = True`` when the two tensors are compatible for tensor addition\n",
        "  - ``condition = False`` when the two tensors are not compatible for tensor addition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_whuZScO4iD"
      },
      "outputs": [],
      "source": [
        "def add_tensor(ten_a, ten_b):\n",
        "  '''\n",
        "  args:\n",
        "    ten_a: a tensor\n",
        "    ten_b: a tensor\n",
        "  return:\n",
        "    a tensor or 'Error'\n",
        "\n",
        "  TODO: implement this\n",
        "  If two tensors cannot be added, return 'Error'\n",
        "  '''\n",
        "\n",
        "  condition = True # replace this line with correct logic\n",
        "\n",
        "\n",
        "  if condition is False:\n",
        "    return 'Error'\n",
        "\n",
        "  return\n",
        "\n",
        "tensor_a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "tensor_b = torch.tensor([[2, 4, 3], [6, 6, 7]])\n",
        "\n",
        "result = add_tensor(tensor_a, tensor_b)\n",
        "print(f\"Input tensor a:\\n{tensor_a}\\nInput tensor b:\\n{tensor_b}\\nResult of adding two tensors:\\n{result}\")\n",
        "\n",
        "tensor_c = torch.randn(3, 3)\n",
        "tensor_d = torch.randn(2, 4)\n",
        "tensor_e = torch.randn(2, 3, 1)\n",
        "tensor_f = torch.randn(2, 3)\n",
        "assert (result == torch.tensor([[3, 6, 6], [10, 11, 13]])).all(), f\"result should be [[3, 6, 6], [10, 11, 13]], but got {result}\"\n",
        "assert add_tensor(tensor_a, tensor_c) == 'Error', f\"result should be 'Error', but got {add_tensor(tensor_a, tensor_c)}\"\n",
        "assert add_tensor(tensor_a, tensor_d) == 'Error', f\"result should be 'Error', but got {add_tensor(tensor_a, tensor_d)}\"\n",
        "assert add_tensor(tensor_a, tensor_e) == 'Error', f\"result should be 'Error', but got {add_tensor(tensor_a, tensor_e)}\"\n",
        "assert add_tensor(tensor_a, tensor_f) != 'Error', f\"result should not be 'Error', but got {add_tensor(tensor_a, tensor_f)}\"\n",
        "\n",
        "print(\"All test cases passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoWs9HEgO4iD"
      },
      "source": [
        "### 3-2. Implementing Element-wise Multiplication\n",
        "- Complete simple element-wise function of two tensors\n",
        "- Complete correct ``condition`` so that you don't get error\n",
        "  - ``condition = True`` when the two tensors are compatible for element-wise multiplication\n",
        "  - ``condition = False`` when the two tensors are not compatible for element-wise multiplication\n",
        "- Element-wise multiplication $\\odot$ of matrix can be defined as below:\n",
        "$\\\\\n",
        "\\left[\\begin{array}{cc}\n",
        "a & b\\\\\n",
        "c & d\n",
        "\\end{array}\\right]\n",
        "\\odot\n",
        "\\left[\\begin{array}{cc}\n",
        "e & f\\\\\n",
        "g & h\n",
        "\\end{array}\\right]\n",
        "=\n",
        "\\left[\\begin{array}{cc}\n",
        "a\\times e & b\\times f\\\\\n",
        "c\\times g & d\\times h\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "\n",
        "- You can use `*` operator for element-wise multiplication in ``torch``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7y-UvXtO4iD"
      },
      "outputs": [],
      "source": [
        "def elementwise_mul_tensor(ten_a, ten_b):\n",
        "  '''\n",
        "  args:\n",
        "    ten_a: a 2D tensor\n",
        "    ten_b: a 2D tensor\n",
        "  return:\n",
        "    a tensor or 'Error'\n",
        "\n",
        "  TODO: implement this\n",
        "  If two tensors cannot be added, return 'Error'\n",
        "  '''\n",
        "\n",
        "  condition = True # replace this line with correct logic\n",
        "\n",
        "  if condition is False:\n",
        "    return 'Error'\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "tensor_a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "tensor_b = torch.tensor([[2, 4, 3], [6, 6, 7]])\n",
        "\n",
        "result = elementwise_mul_tensor(tensor_a, tensor_b)\n",
        "print(f\"Input tensor a:\\n{tensor_a}\\nInput tensor b:\\n{tensor_b}\\nResult of element-wise multiply two tensors:\\n{result}\")\n",
        "\n",
        "tensor_c = torch.randn(3, 3)\n",
        "tensor_d = torch.randn(2, 4)\n",
        "tensor_e = torch.randn(2, 3, 1)\n",
        "tensor_f = torch.randn(2, 3)\n",
        "\n",
        "assert (result == torch.tensor([[2, 8, 9], [24, 30, 42]])).all(), f\"result should be [[2, 8, 9], [24, 30, 42]], but got {result}\"\n",
        "assert elementwise_mul_tensor(tensor_a, tensor_c) == 'Error', f\"result should be 'Error', but got {elementwise_mul_tensor(tensor_a, tensor_c)}\"\n",
        "assert elementwise_mul_tensor(tensor_a, tensor_d) == 'Error', f\"result should be 'Error', but got {elementwise_mul_tensor(tensor_a, tensor_d)}\"\n",
        "assert elementwise_mul_tensor(tensor_a, tensor_e) == 'Error', f\"result should be 'Error', but got {elementwise_mul_tensor(tensor_a, tensor_e)}\"\n",
        "assert elementwise_mul_tensor(tensor_a, tensor_f) != 'Error', f\"result should not be 'Error', but got {elementwise_mul_tensor(tensor_a, tensor_f)}\"\n",
        "\n",
        "print(\"All test cases passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhCdVrNdO4iD"
      },
      "source": [
        "### 3-3. Implementing Matrix Multiplication\n",
        "- Complete simple matrix multiplication function of two tensors\n",
        "- Complete correct ``condition`` so that you don't get error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6yDvQ2HO4iD"
      },
      "outputs": [],
      "source": [
        "def tensor_matrix_mutiplication(ten_a, ten_b):\n",
        "  '''\n",
        "  args:\n",
        "    ten_a: a 2D tensor\n",
        "    ten_b: a 2D tensor\n",
        "  return:\n",
        "    a tensor or 'Error'\n",
        "\n",
        "  TODO: implement this\n",
        "  If two tensors cannot be added, return 'Error'\n",
        "  '''\n",
        "\n",
        "  condition = True # replace this line with correct logic\n",
        "\n",
        "  if condition is False:\n",
        "    return 'Error'\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "tensor_a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "tensor_b = torch.tensor([[2, 4], [6, 6], [7, 8]])\n",
        "\n",
        "result = tensor_matrix_mutiplication(tensor_a, tensor_b)\n",
        "print(f\"Input tensor a:\\n{tensor_a}\\nInput tensor b:\\n{tensor_b}\\nResult of tensor matrix multiplication:\\n{result}\")\n",
        "\n",
        "tensor_c = torch.randint(low=-5, high=5, size=(3, 5))\n",
        "tensor_d = torch.randint(low=-5, high=5, size=(2, 3))\n",
        "tensor_e = torch.randint(low=-5, high=5, size=(4, 3))\n",
        "\n",
        "assert (result == torch.tensor([[35, 40], [80, 94]])).all(), f\"result should be [[35, 40], [80, 94]], but got {result}\"\n",
        "assert tensor_matrix_mutiplication(tensor_a, tensor_c).shape == torch.Size([2, 5]), f\"result should be a tensor of shape (2, 5), but got {tensor_matrix_mutiplication(tensor_a, tensor_c)}\"\n",
        "assert tensor_matrix_mutiplication(tensor_a, tensor_d) == 'Error', f\"result should be 'Error', but got {tensor_matrix_mutiplication(tensor_a, tensor_d)}\"\n",
        "assert tensor_matrix_mutiplication(tensor_a, tensor_e) == 'Error', f\"result should be 'Error', but got {tensor_matrix_mutiplication(tensor_a, tensor_e)}\"\n",
        "\n",
        "print(\"All test cases passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ydwAZRsO4iD"
      },
      "source": [
        "### 3-4. Implementing Tensor Slicing\n",
        "- Complete simple slicing function for a tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVgaIirYO4iE"
      },
      "outputs": [],
      "source": [
        "# Tensor slice example\n",
        "# You do not need to implement anything here.\n",
        "\n",
        "# Assume we have a tensor of shape (3, 4)\n",
        "test_tensor = torch.arange(12).reshape(3, 4)\n",
        "print(f\"atensor:\\n{test_tensor}\")\n",
        "\n",
        "# Indexing\n",
        "print(f\"test_tensor[0] (0th row):\\n  {test_tensor[0]}\")\n",
        "print(f\"test_tensor[1, 2] (1st row, 2nd column):\\n  {test_tensor[1, 2]}\")\n",
        "print(f\"test_tensor[1:, 2] (1st to final row, 2nd column):\\n  {test_tensor[1:, 2]}\")\n",
        "print(f\"test_tensor[:, 1] (all rows, 1st column):\\n  {test_tensor[:, 1]}\")\n",
        "print(f\"test_tensor[1:, 1:] (1st to final row, 1st to final column):\\n  {test_tensor[1:, 1:]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBaAE43TO4iE"
      },
      "outputs": [],
      "source": [
        "# Problem starts here!\n",
        "\n",
        "input_tensor = torch.arange(24).reshape(2, 3, 4)\n",
        "print(f\"input_tensor:\\n{input_tensor}\")\n",
        "\n",
        "desired_output_a = torch.tensor([[[5, 6], [9, 10]], [[17, 18], [21, 22]]])\n",
        "print(f\"desired_output_a:\\n{desired_output_a}\")\n",
        "desired_output_b = torch.tensor([[[19]]])\n",
        "print(f\"desired_output_b:\\n{desired_output_b}\")\n",
        "desired_output_c = torch.tensor([[ 4,  5,  6], [16, 17, 18]])\n",
        "print(f\"desired_output_c:\\n{desired_output_c}\")\n",
        "\n",
        "def answer_to_problem_34(input_tensor):\n",
        "  '''\n",
        "  args:\n",
        "    input_tensor: a 3D tensor of shape (2, 3, 4)\n",
        "    >>> tensor([[[ 0,  1,  2,  3],\n",
        "         [ 4,  5,  6,  7],\n",
        "         [ 8,  9, 10, 11]],\n",
        "\n",
        "        [[12, 13, 14, 15],\n",
        "         [16, 17, 18, 19],\n",
        "         [20, 21, 22, 23]]])\n",
        "  return:\n",
        "    a tuple of tensors\n",
        "    first_tensor: a 3D tensor of shape (2, 2, 2)\n",
        "    >>> tensor([[[ 5,  6],\n",
        "                [ 9, 10]],\n",
        "\n",
        "                [[17, 18],\n",
        "                [21, 22]]])\n",
        "    second_tensor: a 3D tensor of shape (1, 1, 1)\n",
        "    >>> tensor([[[19]]])\n",
        "    third_tensor: a 2D tensor of shape (2, 3)\n",
        "    >>> tensor([[ 4,  5,  6],\n",
        "                [16, 17, 18]])\n",
        "\n",
        "  TODO: complete this function using tensor slicing\n",
        "  '''\n",
        "\n",
        "  return output_a, output_b, output_c\n",
        "\n",
        "output_a, output_b, output_c = answer_to_problem_34(input_tensor)\n",
        "print(f\"output_a:\\n{output_a}\")\n",
        "print(f\"output_b:\\n{output_b}\")\n",
        "print(f\"output_c:\\n{output_c}\")\n",
        "\n",
        "assert (output_a == desired_output_a).all(), f\"Your implementation is wrong. Please try again.\"\n",
        "assert (output_b == desired_output_b).all(), f\"Your implementation is wrong. Please try again. Pay attention to the shape of the tensor.\"\n",
        "assert (output_c == desired_output_c).all(), f\"Your implementation is wrong. Please try again.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zse8JdzOO4iE"
      },
      "source": [
        "### Problem 3-5: Implementing Tensor Transpose and Reshape\n",
        "- Solve the problem using ``atensor.transpose()``, ``atensor.permute()``, or ``atensor.reshape()`` function\n",
        "\n",
        "- $\n",
        "A = \\left[\\begin{array}{cc}\n",
        "1 & 2 & 3\\\\\n",
        "4 & 5 & 6\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "- $A^T = \\left[\\begin{array}{cc}\n",
        "1 & 4\\\\\n",
        "2 & 5\\\\\n",
        "3 & 6\n",
        "\\end{array}\\right]$\n",
        "\n",
        "- $A_{reshape1,6} = \\left[\\begin{array}{cc}\n",
        "1 & 2 & 3 & 4 & 5 & 6\n",
        "\\end{array}\\right]$\n",
        "\n",
        "- $A_{reshape6,1} = \\left[\\begin{array}{cc}\n",
        "1\\\\\n",
        "2\\\\\n",
        "3\\\\\n",
        "4\\\\\n",
        "5\\\\\n",
        "6\n",
        "\\end{array}\\right]$\n",
        "\n",
        "- $A_{reshape3,2} = \\left[\\begin{array}{cc}\n",
        "1 & 2\\\\\n",
        "3 & 4\\\\\n",
        "5 & 6\n",
        "\\end{array}\\right]$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nois9ylyO4iE"
      },
      "outputs": [],
      "source": [
        "# Permute Example\n",
        "# You do not need to implement anything here.\n",
        "\n",
        "test_tensor = torch.arange(24).reshape(2, 3, 4)\n",
        "print(f\"test_tensor:\\n{test_tensor}\")\n",
        "print(f\"test_tensor.shape: {test_tensor.shape}\")\n",
        "\n",
        "permuted_tensor = test_tensor.permute(1, 0, 2) # prev 1st dim become 0th dim, prev 0th dim become 1st dim, prev 2nd dim stay the same\n",
        "print(f\"permuted_tensor (swap 0-th dim and 1-st dim):\\n{permuted_tensor}\")\n",
        "\n",
        "permuted_tensor_b = test_tensor.permute(2, 0, 1) # prev 2nd dim become 0th dim, prev 0th dim become 1st dim, prev 1st dim become 2nd dim\n",
        "print(f\"permuted_tensor_b (0,1,2 to 2,0,1):\\n{permuted_tensor_b}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW89zBSCO4iE"
      },
      "outputs": [],
      "source": [
        "# Reshape example\n",
        "# You do not need to implement anything here.\n",
        "reshaped_tensor = test_tensor.reshape(4, 6)\n",
        "print(f\"reshaped_tensor (to {reshaped_tensor.shape}):\\n{reshaped_tensor}\")\n",
        "\n",
        "reshaped_tensor_b = test_tensor.reshape(3, 8)\n",
        "print(f\"reshaped_tensor_b (to {reshaped_tensor_b.shape}):\\n{reshaped_tensor_b}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XutDcpbwO4iE"
      },
      "outputs": [],
      "source": [
        "# Compare Reshape and Permute example\n",
        "# You do not need to implement anything here.\n",
        "permuted_tensor_c = test_tensor.permute(0, 2, 1)\n",
        "print(f\"permuted_tensor_c (0,1,2 to 0,2,1):\\n{permuted_tensor_c}\")\n",
        "reshaped_tensor_c = test_tensor.reshape(permuted_tensor_c.shape)\n",
        "print(f\"reshaped_tensor_c (to {reshaped_tensor_c.shape}):\\n{reshaped_tensor_c}\")\n",
        "print(\"Two tensors are in the same shape but different values. This is because reshape and permute are different operations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW_DxYENO4iE"
      },
      "outputs": [],
      "source": [
        "# Problem Starts here!\n",
        "\n",
        "# Do not change this value\n",
        "atensor = torch.tensor([[[111, 112, 113, 114],\n",
        "                         [121, 122, 123, 124],\n",
        "                         [131, 132, 133, 134]],\n",
        "                        [[211, 212, 213, 214],\n",
        "                         [221, 222, 223, 224],\n",
        "                         [231, 232, 233, 234]]])\n",
        "\n",
        "def answer_to_problem_35(problem):\n",
        "  '''\n",
        "  args:\n",
        "    problem: a tensor of shape (2, 3, 4)\n",
        "    >>> tensor([[[111, 112, 113, 114],\n",
        "         [121, 122, 123, 124],\n",
        "         [131, 132, 133, 134]],\n",
        "\n",
        "        [[211, 212, 213, 214],\n",
        "         [221, 222, 223, 224],\n",
        "         [231, 232, 233, 234]]])\n",
        "\n",
        "  return:\n",
        "    a tensor\n",
        "    >>> tensor([[111, 211, 121, 221, 131, 231, 112, 212, 122, 222, 132, 232],\n",
        "          [113, 213, 123, 223, 133, 233, 114, 214, 124, 224, 134, 234]])\n",
        "\n",
        "  TODO: complete this function using one permute and one reshape operation.\n",
        "  '''\n",
        "  return\n",
        "\n",
        "result = answer_to_problem_35(atensor)\n",
        "assert (result==torch.tensor([[111, 211, 121, 221, 131, 231, 112, 212, 122, 222, 132, 232],\n",
        "                              [113, 213, 123, 223, 133, 233, 114, 214, 124, 224, 134, 234]])).all() , f\"Your answer is wrong. Please try again. Your answer is {result}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX8pNZ1eO4iE"
      },
      "source": [
        "## Problem 4. Implementing Cosine Similarity\n",
        "- This problem is to practice with tensor handling\n",
        "- Implement cosine similarity function\n",
        "  - $\\text{sim}_{cos}(x, y) = \\frac{x \\cdot y}{||x||_2 ||y||_2}$\n",
        "  - $||x||_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$\n",
        "\n",
        "- Vector normalization: $\\frac{x}{||x||_2}$\n",
        "  - Vector normalization is to make a vector to have a unit length\n",
        "  - After normalization, the vector $x$ has length of 1 ($||x||_2 = 1$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt_lsDNuO4iE"
      },
      "outputs": [],
      "source": [
        "def get_l2_norm_of_vector(ten_a: torch.Tensor) -> torch.Tensor:\n",
        "  '''\n",
        "  args:\n",
        "    ten_a: a tensor of ndim == 1\n",
        "  return:\n",
        "    l2 norm of the ten_a\n",
        "    l2 norm is defined as:\n",
        "    $||x||_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$\n",
        "\n",
        "  TODO: implement this\n",
        "  '''\n",
        "  assert ten_a.ndim == 1\n",
        "\n",
        "  return\n",
        "\n",
        "torch.manual_seed(0)\n",
        "ten_a = torch.rand(10)\n",
        "ten_b = torch.rand(20)\n",
        "\n",
        "print(f\"Input: {ten_a}, L2 norm: {get_l2_norm_of_vector(ten_a)}\")\n",
        "print(f\"Input: {ten_b}, L2 norm: {get_l2_norm_of_vector(ten_b)}\")\n",
        "\n",
        "assert torch.isclose(get_l2_norm_of_vector(ten_a), torch.tensor(1.73478), atol=1e-4), 'Your answer is wrong'\n",
        "assert torch.isclose(get_l2_norm_of_vector(ten_b), torch.tensor(2.38497), atol=1e-4), 'Your answer is wrong'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpGPEfbNO4iE"
      },
      "outputs": [],
      "source": [
        "def normalize_vector(ten_a: torch.Tensor) -> torch.Tensor:\n",
        "  '''\n",
        "  args:\n",
        "    ten_a: a tensor of ndim == 1\n",
        "  return:\n",
        "    a tensor that is normalized version of ten_a\n",
        "    normalized version of ten_a is defined as:\n",
        "    $x_{normalized} = \\frac{x}{||x||_2}$\n",
        "  TODO: implement this using get_l2_norm_of_vector\n",
        "  '''\n",
        "  assert ten_a.ndim == 1\n",
        "  return\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "ten_a = torch.rand(10)\n",
        "ten_b = torch.rand(20)\n",
        "\n",
        "print(f\"Input: {ten_a}, normalized: {normalize_vector(ten_a)}\")\n",
        "print(f\"Input: {ten_b}, normalized: {normalize_vector(ten_b)}\")\n",
        "\n",
        "assert abs(get_l2_norm_of_vector(normalize_vector(ten_a)) - 1) < 1e-4, 'The length of the normalized vector should be 1'\n",
        "assert abs(get_l2_norm_of_vector(normalize_vector(ten_b)) - 1) < 1e-4, 'The length of the normalized vector should be 1'\n",
        "print(\"Test case passed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vudymzh3O4iF"
      },
      "outputs": [],
      "source": [
        "def get_cosine_similarity_of_two_vectors(vec_a, vec_b):\n",
        "  '''\n",
        "  args:\n",
        "    vec_a: a tensor of ndim == 1\n",
        "    vec_b: a tensor of ndim == 1\n",
        "  return:\n",
        "    cosine similarity of vec_a and vec_b\n",
        "    cosine similarity is defined as:\n",
        "    $cos(\\theta) = \\frac{a \\cdot b}{||a||_2 ||b||_2}$\n",
        "  TODO: Implement this using normalize_vector and torch.dot\n",
        "  '''\n",
        "  assert vec_a.ndim == 1\n",
        "  assert vec_b.ndim == 1\n",
        "\n",
        "  return\n",
        "\n",
        "torch.manual_seed(0)\n",
        "ten_a = torch.rand(10)\n",
        "ten_b = torch.rand(10)\n",
        "print(f\"Input: {ten_a}, {ten_b}, cosine similarity: {get_cosine_similarity_of_two_vectors(ten_a, ten_b)}\")\n",
        "assert torch.isclose(get_cosine_similarity_of_two_vectors(ten_a, ten_b), torch.tensor(0.9352), atol=1e-4), 'Your answer is wrong'\n",
        "\n",
        "torch.manual_seed(0)\n",
        "ten_a = torch.rand(5)\n",
        "ten_b = torch.rand(5)\n",
        "print(f\"Input: {ten_a}, {ten_b}, cosine similarity: {get_cosine_similarity_of_two_vectors(ten_a, ten_b)}\")\n",
        "assert torch.isclose(get_cosine_similarity_of_two_vectors(ten_a, ten_b), torch.tensor(0.7315), atol=1e-4), 'Your answer is wrong'\n",
        "\n",
        "print(\"Test case passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jhs2S6aO4iF"
      },
      "source": [
        "### Problem 4-2. Normalizing Matrix (Tensor)\n",
        "- Normalizing matrix is to make each row or column of a matrix to have a unit length\n",
        "  - You have to select which dimension to normalize\n",
        "    - This is ``dim`` argument.\n",
        "    - ``dim=0``: calculate norm through dim=0.\n",
        "    - ``dim=1``: calculate norm through dim=1.\n",
        "- Examples:\n",
        "```\n",
        "A = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "A_norm_0 = normalize_tensor(A, dim=0)\n",
        "A_norm_1 = normalize_tensor(A, dim=1)\n",
        "```\n",
        "$\n",
        "A = \\left[\\begin{array}{cc}\n",
        "1 & 2 & 3\\\\\n",
        "4 & 5 & 6\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "\n",
        "$\n",
        "A_{norm_0} = \\left[\\begin{array}{cc}\n",
        "\\frac{1}{\\sqrt{1^2 + 4^2}} & \\frac{2}{\\sqrt{2^2 + 5^2}} & \\frac{3}{\\sqrt{3^2 + 6^2}}\\\\\n",
        "\\frac{4}{\\sqrt{1^2 + 4^2}} & \\frac{5}{\\sqrt{2^2 + 5^2}} & \\frac{6}{\\sqrt{3^2 + 6^2}}\\\\\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "\n",
        "$\n",
        "A_{norm_1} = \\left[\\begin{array}{cc}\n",
        "\\frac{1}{\\sqrt{1^2 + 2^2 + 3^2}} & \\frac{2}{\\sqrt{1^2 + 2^2 + 3^2}} & \\frac{3}{\\sqrt{1^2 + 2^2 + 3^2}}\\\\\n",
        "\\frac{4}{\\sqrt{4^2 + 5^2 + 6^2}} & \\frac{5}{\\sqrt{4^2 + 5^2 + 6^2}} & \\frac{6}{\\sqrt{4^2 + 5^2 + 6^2}}\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zqM73f-O4iF"
      },
      "outputs": [],
      "source": [
        "def normalize_tensor(mat:torch.Tensor, dim:int):\n",
        "  '''\n",
        "  args:\n",
        "    mat: a tensor of arbitrary shape\n",
        "    dim: the dimension to normalize\n",
        "  return:\n",
        "    a tensor that is normalized version of mat\n",
        "    among the dimensions,\n",
        "    normalized version of mat is defined as:\n",
        "    $x_{normalized} = \\frac{x}{||x||_2}$\n",
        "  '''\n",
        "  assert dim < mat.ndim\n",
        "\n",
        "  # TODO: implement this without using torch.norm function\n",
        "  # You can use torch.sum(), torch.sqrt()\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "ten_a = torch.randn(3, 4)\n",
        "ten_b = torch.randn(2, 5, 4)\n",
        "print(f\"Input:\\n{ten_a},\\nnormalized in dim 0:\\n{normalize_tensor(ten_a, 0)}\\nnormalized in dim 1:\\n{normalize_tensor(ten_a, 1)}\")\n",
        "print(f\"Input:\\n{ten_b},\\nnormalized:\\n{normalize_tensor(ten_b, 0)}\\nnormalized in dim 1:\\n{normalize_tensor(ten_b, 1)}\\nnormalized in dim 2:\\n{normalize_tensor(ten_b, 2)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p66HyLf5O4iF"
      },
      "outputs": [],
      "source": [
        "# Test cases\n",
        "\n",
        "torch.manual_seed(0)\n",
        "ten_a = torch.randn(3, 4)\n",
        "ten_b = torch.randn(2, 5, 4)\n",
        "\n",
        "answer_a = torch.tensor([[[ 0.7640, -0.1976, -0.9495,  0.5525],\n",
        "                          [-0.5377, -0.9419,  0.1758,  0.8145],\n",
        "                          [-0.3566, -0.2716, -0.2600,  0.1769]]])\n",
        "answer_b = torch.tensor([[ 0.5615, -0.1069, -0.7939,  0.2071],\n",
        "                         [-0.5424, -0.6995,  0.2017,  0.4192],\n",
        "                         [-0.6956, -0.3901, -0.5770,  0.1761]])\n",
        "answer_c = torch.tensor([[[ 0.9374, -0.2263,  0.8385,  0.4780],\n",
        "                          [ 0.2807,  0.6889, -0.1281, -0.0862],\n",
        "                          [ 0.5333,  0.4403,  0.9733,  0.1581],\n",
        "                          [ 0.3547, -0.6005, -0.8686, -0.9775],\n",
        "                          [-0.1983, -0.5543,  0.9701,  0.3067]],\n",
        "\n",
        "                          [[-0.3484, -0.9741,  0.5449,  0.8784],\n",
        "                          [-0.9598,  0.7248,  0.9918,  0.9963],\n",
        "                          [-0.8459,  0.8978, -0.2297,  0.9874],\n",
        "                          [-0.9350, -0.7997, -0.4955, -0.2109],\n",
        "                          [-0.9801,  0.8323, -0.2425,  0.9518]]])\n",
        "answer_d = torch.tensor([[[ 0.3022, -0.1018,  0.9321,  0.1718],\n",
        "                          [ 0.1832,  0.9625, -0.1579, -0.1229],\n",
        "                          [ 0.3662,  0.4947,  0.7879,  0.0211],\n",
        "                          [ 0.2401, -0.1604, -0.3268, -0.8999],\n",
        "                          [-0.2178, -0.7493,  0.5678,  0.2620]],\n",
        "\n",
        "                          [[-0.1371, -0.5349,  0.7394,  0.3852],\n",
        "                          [-0.2822,  0.4561,  0.5507,  0.6395],\n",
        "                          [-0.4897,  0.8505, -0.1567,  0.1112],\n",
        "                          [-0.8789, -0.2965, -0.2588, -0.2695],\n",
        "                          [-0.6109,  0.6384, -0.0805,  0.4613]]])\n",
        "\n",
        "assert torch.allclose(normalize_tensor(ten_a, 0), answer_a, atol=1e-3), 'Your answer is wrong'\n",
        "assert torch.allclose(normalize_tensor(ten_a, 1), answer_b, atol=1e-3), 'Your answer is wrong'\n",
        "assert torch.allclose(normalize_tensor(ten_b, 0), answer_c, atol=1e-3), 'Your answer is wrong'\n",
        "assert torch.allclose(normalize_tensor(ten_b, 2), answer_d, atol=1e-3), 'Your answer is wrong'\n",
        "\n",
        "print(\"Test cases passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfqSgEAuO4iF"
      },
      "source": [
        "### Problem 4-3. Implementing Cosine Similarity between two matrices\n",
        "- Here, you will implement calculating cosine similarity between two matrices, using for loop or matrix multiplication\n",
        "- Cosine similarity between two matrices can be defined as below:\n",
        "\n",
        "$\n",
        "A = \\left[\\begin{array}{c}\n",
        "\\bf{x_1} \\\\  \n",
        "\\bf{x_2} \\\\\n",
        "\\bf{x_3}\\\\\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "$\n",
        "B = \\left[\\begin{array}{c}\n",
        "\\bf{y_1}\\\\\n",
        "\\bf{y_2}\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        ",where each of $\\bf{x_1}, \\bf{x_2}, \\bf{x_3}, \\bf{y_1}, \\bf{y_2}$ is a row vector, cosine similarity between $A$ and $B$ can be defined as below:\n",
        "\n",
        "$\n",
        "CosineSimilarity(A, B) = \\left[\\begin{array}{cc}\n",
        "\\text{sim}_{cos}(\\bf{x_1}, \\bf{y_1}) & \\text{sim}_{cos}(\\bf{x_1}, \\bf{y_2})\\\\\n",
        "\\text{sim}_{cos}(\\bf{x_2}, \\bf{y_1}) & \\text{sim}_{cos}(\\bf{x_2}, \\bf{y_2})\\\\\n",
        "\\text{sim}_{cos}(\\bf{x_3}, \\bf{y_1}) & \\text{sim}_{cos}(\\bf{x_3}, \\bf{y_2})\\\\\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "\n",
        "- Here is aonther example with concrete values:\n",
        "\n",
        "$\n",
        "A = \\left[\\begin{array}{cc}\n",
        "0 & 1 \\\\  \n",
        "1 & 0 \\\\\n",
        "-1& 0\\\\\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "$\n",
        "B = \\left[\\begin{array}{cc}\n",
        "1 & 0 \\\\  \n",
        "0 & -1 \\\\\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "$\n",
        "CosineSimilarity(A, B) = \\left[\\begin{array}{cc}\n",
        "\\text{sim}_{cos}([0, 1], [1, 0]) & \\text{sim}_{cos}([0, 1], [0, -1])\\\\\n",
        "\\text{sim}_{cos}([1, 0], [1, 0]) & \\text{sim}_{cos}([1, 0], [0, -1])\\\\\n",
        "\\text{sim}_{cos}([-1, 0], [1, 0]) & \\text{sim}_{cos}([-1, 0], [0, -1])\\\\\n",
        "\\end{array}\\right]\n",
        "= \\left[\\begin{array}{cc}\n",
        "0 & -1\\\\\n",
        "1 & 0\\\\\n",
        "-1 & 0\\\\\n",
        "\\end{array}\\right]\n",
        "$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efcN3lUYO4iH"
      },
      "outputs": [],
      "source": [
        "def get_cosine_similarity_of_two_matrices_by_for_loop(mat_a, mat_b):\n",
        "  '''\n",
        "  args:\n",
        "    mat_a: a 2D tensor\n",
        "    mat_b: a 2D tensor\n",
        "  return:\n",
        "    cosine similarity of mat_a and mat_b\n",
        "    cosine similarity is defined as:\n",
        "    $cos(\\theta) = \\frac{a \\cdot b}{||a||_2 ||b||_2}$\n",
        "\n",
        "  TODO: Compute cosine similarity of two matrices using for loop\n",
        "  use normalize_tensor() and torch.dot(), or\n",
        "  '''\n",
        "  assert mat_a.ndim == 2\n",
        "  assert mat_b.ndim == 2\n",
        "  assert mat_a.shape[1] == mat_b.shape[1]\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "ten_a = torch.randn(6, 3)\n",
        "ten_b = torch.randn(4, 3)\n",
        "print(f\"Input A:\\n{ten_a},\\nInput_B:\\n{ten_b}\\ncosine similarity:\\n{get_cosine_similarity_of_two_matrices_by_for_loop(ten_a, ten_b)}\")\n",
        "\n",
        "answer = torch.tensor([[-0.7931,  0.5368,  0.0880,  0.1611],\n",
        "                      [ 0.3438,  0.0073,  0.4938,  0.4885],\n",
        "                      [ 0.8885, -0.2307, -0.1930, -0.5425],\n",
        "                      [-0.6407,  0.2590, -0.2294, -0.1603],\n",
        "                      [ 0.8627, -0.8801, -0.7024, -0.7978],\n",
        "                      [ 0.4416, -0.1207, -0.4180, -0.6963]])\n",
        "\n",
        "assert torch.allclose(get_cosine_similarity_of_two_matrices_by_for_loop(ten_a, ten_b), answer, atol=1e-3), 'Your answer is wrong'\n",
        "print(\"Test case passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RugD0DE3O4iQ"
      },
      "outputs": [],
      "source": [
        "def get_consine_similarity_of_two_matrices(mat_a: torch.Tensor, mat_b: torch.Tensor):\n",
        "  '''\n",
        "  args:\n",
        "    mat_a: a tensor of two dimensions\n",
        "    mat_b: a tensor of two dimensions\n",
        "    dim: the dimension to calculate cosine similarity\n",
        "  return:\n",
        "    cosine similarity between every vector of mat_a and mat_b\n",
        "    cosine similarity is defined as:\n",
        "    $cos(\\theta) = \\frac{a \\cdot b}{||a||_2 ||b||_2}$\n",
        "  TODO: Implement this using normalize_tensor() and torch.mm()\n",
        "  '''\n",
        "  assert mat_a.ndim == 2\n",
        "  assert mat_b.ndim == 2\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "ten_a = torch.randn(6, 3)\n",
        "ten_b = torch.randn(4, 3)\n",
        "\n",
        "print(f\"Input A:\\n{ten_a},\\nInput_B:\\n{ten_b}\\ncosine similarity\\n{get_consine_similarity_of_two_matrices(ten_a, ten_b)}\")\n",
        "\n",
        "\n",
        "\n",
        "assert torch.allclose(get_consine_similarity_of_two_matrices(ten_a, ten_b), answer, atol=1e-3), 'Your answer is wrong'\n",
        "print(\"Test case passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gS5iDNiO4iQ"
      },
      "source": [
        "## Problem 5. Implementing Multi Layer Perceptron with PyTorch\n",
        "- Multi Layer Perceptron (MLP) is a simple neural network model that consists of multiple layers of perceptrons (neurons).\n",
        "- In this problem, you will implement MLP with PyTorch\n",
        "\n",
        "- You have to implement a network of following diagram\n",
        "- ![img](https://github.com/jdasam/mas1004/blob/2023/assign1_diagram.png?raw=true)\n",
        "  - The network consists of three layers\n",
        "  - Input has 1 dimension\n",
        "  - Layer 1 has 6 neurons\n",
        "  - Layer 2 has 4 neurons\n",
        "  - Layer 3 has 1 neurons\n",
        "    - This is the output of the network\n",
        "  - Each layer is fully connected to the next layer\n",
        "  - Each layer has a **bias** term\n",
        "  - Each layer has a **ReLU** activation function\n",
        "\n",
        "- Implement this using ``nn.Module`` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLxgy5ucO4iQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module): # inherit from nn.Module\n",
        "  def __init__(self):\n",
        "    super().__init__() # call the __init__() of nn.Module\n",
        "\n",
        "    # TODO: define layers with nn.Linear()\n",
        "    # Caution: You have to strictly follow the order of layers in declaration\n",
        "    # So that the assertion code below does not fail.\n",
        "    self.layer1 = None # replace this line with correct code\n",
        "    self.layer2 = None # replace this line with correct code\n",
        "    self.layer3 = None # replace this line with correct code\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    '''\n",
        "    args:\n",
        "      x: a 2D tensor\n",
        "    return:\n",
        "      a 2D tensor\n",
        "      Output of the model\n",
        "      x -> self.layer1 -> ReLU -> self.layer2 -> ReLU -> self.layer3 -> return\n",
        "\n",
        "    TODO: Implement this using self.layer1, self.layer2, self.layer3, torch.relu()\n",
        "    CAUTION: Do not forget to use torch.relu() after each layer except the last layer.\n",
        "    '''\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "model = MyModel()\n",
        "test_input = torch.randn(5, 1)\n",
        "test_input2 = torch.randn(16, 1)\n",
        "test_out = model(test_input)\n",
        "test_out2 = model(test_input2)\n",
        "# Following code is for testing your implementation\n",
        "assert hasattr(model, 'layer1'), 'layer1 is not defined'\n",
        "assert hasattr(model, 'layer2'), 'layer2 is not defined'\n",
        "assert hasattr(model, 'layer3'), 'layer3 is not defined'\n",
        "assert isinstance(model.layer1, nn.Linear), 'layer1 should be nn.Linear'\n",
        "assert isinstance(model.layer2, nn.Linear), 'layer2 should be nn.Linear'\n",
        "assert isinstance(model.layer3, nn.Linear), 'layer3 should be nn.Linear'\n",
        "assert model.layer1.in_features == 1, 'layer1 should have 1 input feature'\n",
        "assert model.layer1.out_features == 6, 'layer1 should have 6 output features'\n",
        "assert model.layer2.in_features == 6, 'layer2 should have 6 input features'\n",
        "assert model.layer2.out_features == 4, 'layer2 should have 4 output features'\n",
        "assert model.layer3.in_features == 4, 'layer3 should have 4 input features'\n",
        "assert model.layer3.out_features == 1, 'layer3 should have 1 output feature'\n",
        "\n",
        "assert torch.allclose(test_out, torch.tensor([-0.6696, -0.5911, -0.7009, -0.6649, -0.5941]).unsqueeze(1), atol=1e-4), 'Your forward() is wrong'\n",
        "assert torch.allclose(test_out2, torch.tensor([-0.5775, -0.5609, -0.5633, -0.6565, -0.6954, -0.6512, -0.5585, -0.5615,\n",
        "        -0.6353, -0.6253, -0.5715, -0.6060, -0.6122, -0.6473, -0.6873, -0.6184]).unsqueeze(1), atol=1e-4), 'Your forward() is wrong'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn6UbPTyO4iQ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "model = MyModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "x_tensor = torch.linspace(-5, 5, 500).unsqueeze(1)\n",
        "y = func_c.calculate_list_input(x_tensor.squeeze(1).tolist())\n",
        "y_tensor = torch.tensor(y).unsqueeze(1)\n",
        "\n",
        "\n",
        "for epoch in range(1500):\n",
        "  optimizer.zero_grad()\n",
        "  output = model(x_tensor)\n",
        "  loss = criterion(output, y_tensor)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch}, loss: {loss.item()}\")\n",
        "\n",
        "plt.plot(x_tensor, y_tensor, label='ground truth')\n",
        "plt.plot(x_tensor, output.detach(), label='prediction')\n",
        "plt.legend()\n",
        "\n",
        "assert loss.item() < 0.03, \"Your loss seems too high. Please check your implementation.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Complete py file\n",
        "- download `assignment_1.py` file using the code below.\n",
        "- copy and paste the code you implemented in the notebook to the `assignment_1.py` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/jdasam/mas1004/refs/heads/2024/assignment_1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run the py file to check if it is working\n",
        "!python3 assignment_1.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
