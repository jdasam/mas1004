{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/mas1004-2023/blob/main/assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7oN9TOC3WQr"
      },
      "source": [
        "# Assignment 2: Image Classification\n",
        "- In this assignment, you have to train an image classification model with __your own data__\n",
        "- You have to submit 1) a report, 2) code, and 3) data\n",
        "  1. Report in free format (submit in PDF)\n",
        "    - 1) Introduce why you selected these four categories\n",
        "      - Why is it interesting topic to you?\n",
        "      - What kind of visual characteristics would the model use for the classification?\n",
        "    - 2) Describe the very first result of training the model, especially about the error cases\n",
        "      - Is there overfitting? Do you need more epochs to train the model?\n",
        "      - Based on the error cases of the model, explain why the model makes such mistakes in your opinion\n",
        "      - Describe why we use pre-trained model for image classification, instead of random initialization\n",
        "    - 3) Explain your criteria for data cleaning\n",
        "    - 4) Describe the result after training the model with data cleaning\n",
        "    - 5) Test your model with your custom image and explain the result of prediction\n",
        "      - Why it failed? Guess what is the important pattern/characteristics in the image for model to classify it\n",
        "      - It is important to test images that can provide you some clue, or give evidence for your hypothesis\n",
        "\n",
        "    - Your submission would be evaluated mainly with the report\n",
        "    - Please include the plot figures that were generated during the experiment in your report\n",
        "  2. code (submit in ipynb)\n",
        "  3. data (submit in zip files). You can submit as a downloadable link if the zip size is too large\n",
        "\n",
        "- Evaluation Criteria:\n",
        "  1. How interesting is the selected topic\n",
        "  2. How well did you analyze the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfl16FmrrY82"
      },
      "source": [
        "## 0. Install Library and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igvvejFk2qRW",
        "outputId": "3cf5ce73-e38e-40d7-fd91-0f89a02360bd"
      },
      "outputs": [],
      "source": [
        "!pip install -q jmd_imagescraper\n",
        "\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from jmd_imagescraper.core import duckduckgo_search\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XypX1h6KrY83"
      },
      "source": [
        "## 1. Configure Settings\n",
        "- 1) Select the storage type\n",
        "  - Since Colab storage is volatile, your image dataset or model would disappear after the session ends.\n",
        "  - There are two options to save the data permanently:\n",
        "    1. Save your data in your local computer by downloading it from Colab. select `SAVE_TYP='local'`\n",
        "    2. Save your data in your Google Drive storage. select `SAVE_TYP='google_drive'`\n",
        "  - If you are running on your local computer, use `SAVE_TYP='local'`\n",
        "- 2) Select Number of images you want to collect\n",
        "  - `NUM_IMG` will define the number of image per category for crawling\n",
        "  - `100<=NUM_IMG<=500` of your choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9U-Byv9rY83",
        "outputId": "230fb85b-46c6-45f0-de62-ccf4760c0df0"
      },
      "outputs": [],
      "source": [
        "# SAVE_TYP = 'local'\n",
        "SAVE_TYP = 'google_drive'\n",
        "NUM_IMG = 100 # This will define how many images you will download\n",
        "\n",
        "try: # check whether you are running the notebook on colab\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "  if SAVE_TYP == 'local': # if you selected to save it in local\n",
        "    from google.colab import files\n",
        "  else:\n",
        "    from google.colab import drive # if you selected to save it in your Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    GGL_DIR = Path('/content/drive/MyDrive/Data_AI_Assignment2/')\n",
        "    GGL_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "IMG_DIR = Path('images')\n",
        "if IN_COLAB and SAVE_TYP==\"google_drive\":\n",
        "  PLOT_DIR = GGL_DIR / \"plots/\"\n",
        "else:\n",
        "  PLOT_DIR = Path('plots')\n",
        "PLOT_DIR.mkdir(exist_ok=True)\n",
        "DEL_DIR = IMG_DIR / 'deleted'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-PA5Xi536L2"
      },
      "source": [
        "## Problem 1: Collect Data \n",
        "- You have to select 4 image categories of your own choice\n",
        "- The selected categories will be used as an image class for the classification model\n",
        "- TODO:\n",
        "  - Explain why did you choose these categories for image classification\n",
        "    - Why is it interesting topic to you?\n",
        "    - What kind of visual characteristics would the model use for the classification?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab8_KzBs3gi9"
      },
      "outputs": [],
      "source": [
        "def configure_image_categories():\n",
        "  '''\n",
        "  input: None\n",
        "  output: List of strings that contains 4 classes\n",
        "\n",
        "  example: image_keywords = ['football', 'basketball', 'baseball', 'volleyball']\n",
        "  '''\n",
        "  # TODO: Complete the function\n",
        "  image_keywords = []\n",
        "  return image_keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF5BKi2Gu2gB"
      },
      "source": [
        "## Image Crawling\n",
        "- Following code will automatically crawl the images with the keyword you have choosen\n",
        "- After running it, it will automatically split train and valid to ratio of 8:2\n",
        "  - Training data will be located `images/train`\n",
        "  - Validation data will be locatd `images/valid`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKr6IdVFG0TN"
      },
      "source": [
        "#### Pre-defined Functions (run it without opening it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7IKt6sbrY86"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "You don't have to change this cell\n",
        "'''\n",
        "\n",
        "def get_image_using_duckduckgo(img_dir:Path, image_types: list, num_img:int):\n",
        "  for typ in image_types:\n",
        "    duckduckgo_search(img_dir, typ, typ, max_results=NUM_IMG)\n",
        "    typ_dir = img_dir / typ\n",
        "\n",
        "def split_train_and_valid(img_dir, image_types, random_seed=0):\n",
        "  random.seed(0)\n",
        "  valid_indices = random.sample(range(NUM_IMG), NUM_IMG//5)\n",
        "  image_keywords = [child.name for child in img_dir.iterdir() if child.is_dir()]\n",
        "  for typ in image_keywords:\n",
        "    typ_dir = img_dir / typ\n",
        "    train_dir = img_dir / 'train' / typ\n",
        "    test_dir = img_dir / 'test' / typ\n",
        "    train_dir.mkdir(parents=True, exist_ok=True)\n",
        "    test_dir.mkdir(parents=True, exist_ok=True)\n",
        "    img_files = list(typ_dir.rglob('*.jpg'))\n",
        "    valid_imgs = [img_files[i] for i in valid_indices]\n",
        "    for fn in valid_imgs:\n",
        "      shutil.move(fn, test_dir/fn.name)\n",
        "    img_files = list(typ_dir.rglob('*.jpg'))\n",
        "    for fn in img_files:\n",
        "      shutil.move(fn, train_dir/fn.name)\n",
        "    os.rmdir(typ_dir)\n",
        "\n",
        "def save_fig_with_date(figname):\n",
        "  plt.savefig(PLOT_DIR/f\"{figname}_{time.ctime().split(' ')[-2].replace(':', '')}.png\")\n",
        "\n",
        "def file_name_with_date(filename):\n",
        "  filename = Path(filename)\n",
        "  return f\"{filename.stem}_{'_'.join(time.ctime().split(' ')[1:4])}{filename.suffix}\"\n",
        "\n",
        "def save_file(fn):\n",
        "  if IN_COLAB: # If you are running this notebook on Colab \n",
        "    if SAVE_TYP == 'local': # if you selected to save it in local\n",
        "      files.download(fn)   # download the file to your local computer \n",
        "    else:\n",
        "      shutil.copy(fn, GGL_DIR)  # copy the file to your google drive\n",
        "\n",
        "def plot_random_sampled_images(img_dir, ncols=4, nrows=5,random_seed=0):\n",
        "  # first, list all jpg files in the img_dir\n",
        "  list_of_image_files = list(img_dir.rglob(\"*.jpg\"))\n",
        "  # randomly shuffle the order of image files\n",
        "  # so that we can sample different images every time\n",
        "  # but controlled by random seed \n",
        "  # computer's random algorithm is pseudo random\n",
        "  random.seed(random_seed)\n",
        "  random.shuffle(list_of_image_files)\n",
        "\n",
        "  # prepare empty canvas\n",
        "  plt.figure(figsize=(ncols*5,nrows*4))\n",
        "\n",
        "  # for each coloumn and row, load image and plot image on the canvas\n",
        "  for i in range(ncols*nrows):\n",
        "    fname = list_of_image_files[i]\n",
        "    image = Image.open(fname)\n",
        "    plt.subplot(nrows,ncols, i+1) \n",
        "    plt.imshow(image)\n",
        "    plt.title('/'.join(str(fname.parent).split('/')[-2:]))\n",
        "    plt.axis('off')\n",
        "  save_fig_with_date(\"dataset_check\") # save figure as png in PLOT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XggILwcy5q_n",
        "outputId": "69f49216-55ba-4cc1-f43b-47d2ec55caa5"
      },
      "outputs": [],
      "source": [
        "# How to control random results\n",
        "random.seed(0)\n",
        "random.random(), random.random(), random.random() # return random float between 0 and 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyAvAZuP66tK"
      },
      "source": [
        "### Download or Unzip\n",
        "- If this is your first time to download the dataset, it will automatically download the images fro duckduckgo search\n",
        "- If you already ran the crawling code and have `image_data.zip` file in your local or google drive, you can upload it to the current Colab storage and unzip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPyQP4yF3V-R",
        "outputId": "a06a093b-7489-4530-ffbc-a539b4e405de"
      },
      "outputs": [],
      "source": [
        "image_types = configure_image_categories()\n",
        "print(image_types)\n",
        "assert len(image_types)==4, \"The length of image types has to be 4\"\n",
        "assert all( isinstance(typ, str) for typ in image_types), \"Every element of image_types has to be string\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7osSmOempf"
      },
      "source": [
        "- If you want to delete every file in the `images/`, you can run following code\n",
        "  - `!rm -rf images/`\n",
        "  - It will forcely remove every file and directory in images. So please be careful when using it\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfAqFJe1e8dy"
      },
      "outputs": [],
      "source": [
        "# delete the images/ folder if you want to re-compose your dataset\n",
        "# !rm -rf images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuQDmhtp4y99"
      },
      "outputs": [],
      "source": [
        "get_image_using_duckduckgo(IMG_DIR, image_types, NUM_IMG) # Download image files\n",
        "split_train_and_valid(IMG_DIR, image_types) # Split train and valid into different directories\n",
        "os.system(f\"zip -rq image_data.zip {IMG_DIR}\") # Make zip file that contains images directory\n",
        "save_file(\"image_data.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t8F2WLoe8wK"
      },
      "source": [
        "- Following code will download the dataset or unzip the pre-saved zip files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFtebCv_rY87",
        "outputId": "23e4fee7-a9ac-4ed3-dd82-76ea79a3290a"
      },
      "outputs": [],
      "source": [
        "if not IMG_DIR.exists(): # If there is no image directory\n",
        "  if Path(\"image_data_cleaned.zip\").exists(): # if there is already cleaned dataset\n",
        "    print(\"Extracting image_data_cleaned.zip\")\n",
        "    os.system(\"unzip -q image_data_cleaned.zip\") # unzip image_data_cleaned.zip\n",
        "  elif IN_COLAB and SAVE_TYP == \"google_drive\" and (GGL_DIR/\"image_data_cleaned.zip\").exists(): # if there is already cleaned dataset on GD\n",
        "    print(\"Extracting image_data_cleaned.zip from Google Drive\")\n",
        "    shutil.copy(str(GGL_DIR/\"image_data_cleaned.zip\"), \"/content/\") # copy it to colab storage\n",
        "    os.system(\"unzip -q image_data_cleaned.zip\") # and unzip it\n",
        "  elif Path(\"image_data.zip\").exists(): # If image_data.zip file exists\n",
        "    print(\"Extracting image_data.zip\")\n",
        "    os.system(\"unzip -q image_data.zip\") # Unzip the zip file\n",
        "  elif IN_COLAB and SAVE_TYP == \"google_drive\" and (GGL_DIR/\"image_data.zip\").exists():\n",
        "    print(\"Extracting image_data.zip from Google Drive\")\n",
        "    shutil.copy(str(GGL_DIR/\"image_data.zip\"), \"/content/\")\n",
        "    os.system(\"unzip -q image_data.zip\")\n",
        "  else: # If there is no image directory and also no image_data.zip\n",
        "    print(\"Downloading images from DuckDuckGo\")\n",
        "    get_image_using_duckduckgo(IMG_DIR, image_types, NUM_IMG) # Download image files\n",
        "    split_train_and_valid(IMG_DIR, image_types) # Split train and valid into different directories\n",
        "    os.system(f\"zip -rq image_data.zip {IMG_DIR}\") # Make zip file that contains images directory\n",
        "    save_file(\"image_data.zip\")\n",
        "else:\n",
        "  print(f\"IMG_DIR ({IMG_DIR}) already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMCVfaR0rY89"
      },
      "source": [
        "### Plot your Dataset\n",
        "- It is always important to check your dataset in detail\n",
        "- Run the script below and see the result\n",
        "  - The figure will automatically saved as png with current time to `PLOT_DIR`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cukbNQprY89"
      },
      "outputs": [],
      "source": [
        "plot_random_sampled_images(IMG_DIR, ncols=4, nrows=5, random_seed=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFg4_4AsyAFE"
      },
      "source": [
        "## Problem 2: Report the first training result\n",
        "- You don't have to change the code for Problem 2 if you have made the correct dataset on Problem 1\n",
        "- TODO: \n",
        "  - Explain how the training procedure looks like. Is there overfitting? Do you need more epochs to train the model?\n",
        "  - Based on the error cases of the model, explain why the model makes such mistakes in your opinion\n",
        "  - Explain why you need to use pre-trained weights, instead of random initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pou71N2E3318"
      },
      "source": [
        "### Dataset Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRTmdt7a3qO1"
      },
      "outputs": [],
      "source": [
        "class ImageSet:\n",
        "  def __init__(self, path_dir, file_types=['jpg', 'png'], transform=None):\n",
        "    self.path = Path(path_dir)\n",
        "    self.image_fns = sorted(item for y in [list(self.path.rglob(f'*.{x}')) for x in file_types] for item in y) \n",
        "    self.classes = sorted(list(set([x.parent.name for x in self.image_fns])))\n",
        "    self.cls2idx = {k: i for i, k in enumerate(self.classes)}\n",
        "    self.transform = transforms.Compose([\n",
        "                        transforms.Resize(256),\n",
        "                        transforms.CenterCrop(224),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_fns)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.image_fns[idx]\n",
        "    img = self.transform(Image.open(img_path).convert('RGB'))\n",
        "    cls = img_path.parent.name\n",
        "    return img, self.cls2idx[cls]\n",
        "\n",
        "trainset = ImageSet(IMG_DIR/'train')\n",
        "testset = ImageSet(IMG_DIR/'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxDwf939rY8-"
      },
      "source": [
        "Check the Batch result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSM9ZQVMCxky"
      },
      "outputs": [],
      "source": [
        "tensor2pil = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0, 0, 0], std=[4.3668, 4.4643, 4.4444]),\n",
        "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
        "    transforms.ToPILImage()\n",
        "])\n",
        "\n",
        "\n",
        "def show_batch(dataloader, ncols=4, nrows=5, random_seed=0):\n",
        "  torch.manual_seed(random_seed)\n",
        "  images, labels = next(iter(dataloader))\n",
        "  plt.figure(figsize=(ncols*5,nrows*4))\n",
        "  for i in range(ncols*nrows):\n",
        "    plt.subplot(nrows, ncols, i+1)\n",
        "    pil_img = tensor2pil(images[i])\n",
        "    plt.imshow(pil_img)\n",
        "    plt.title(trainset.classes[labels[i]])\n",
        "    plt.axis('off')\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pyF7_kQCxky"
      },
      "outputs": [],
      "source": [
        "show_batch(train_loader, random_seed=0)\n",
        "save_fig_with_date(\"train_batch\") # Don't forget to always save the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6ENxoM98mI_"
      },
      "source": [
        "### Trainer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypj6fWaOCxky"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "  def __init__(self, model, train_loader, valid_loader, model_name='resnet'):\n",
        "    self.model = model\n",
        "    self.train_loader = train_loader\n",
        "    self.valid_loader = valid_loader\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.model.to(self.device)\n",
        "    self.criterion = nn.NLLLoss()\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "    self.best_loss = np.inf\n",
        "    self.best_acc = 0.0\n",
        "    self.train_losses = []\n",
        "    self.valid_losses = []\n",
        "    self.train_accs = []\n",
        "    self.valid_accs = []\n",
        "    self.model_name = model_name\n",
        "\n",
        "  def validation(self):\n",
        "    self.model.eval() # change the model from train mode to evaluation mode\n",
        "    # Some models work in different ways based on whtehter it is on training step\n",
        "    # or on inference step\n",
        "\n",
        "    # In validation step, you don't have to calculate the gradient\n",
        "    # with torch.no_grad():\n",
        "\n",
        "    current_loss = 0\n",
        "    num_total_correct_pred = 0\n",
        "    with torch.inference_mode(): # every torch computation under this indent\n",
        "    # will be run without calculating the gradient or computation history\n",
        "      for batch in self.valid_loader:\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(self.device), labels.to(self.device)\n",
        "        outputs = self.model(images)\n",
        "        probs = torch.softmax(outputs, dim=-1)\n",
        "        log_probs = torch.log(probs)\n",
        "\n",
        "        loss = self.criterion(log_probs, labels)\n",
        "        predicted_classes = torch.argmax(outputs, dim=-1)\n",
        "        num_acc_pred = (predicted_classes == labels.to(self.device)).sum()\n",
        "        #num_acc_pred is on self.device\n",
        "        num_total_correct_pred += num_acc_pred.item()\n",
        "        # in validation stage, we don't care about single batch's loss\n",
        "        # we want to see the result for total images of validation set\n",
        "\n",
        "        current_loss += loss.item() * len(labels)\n",
        "        # instead of adding the mean loss, we add sum of loss\n",
        "        # because the batch size can be different\n",
        "    mean_loss = current_loss / len(self.valid_loader.dataset)\n",
        "    mean_acc = num_total_correct_pred / len(self.valid_loader.dataset) # number of total datasample in the validation loader\n",
        "    return mean_loss, mean_acc\n",
        "    # return {'loss': mean_loss, 'acc': mean_acc}\n",
        "\n",
        "\n",
        "\n",
        "  def train_by_number_of_epochs(self, num_epochs):\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "      self.model.train()\n",
        "      for batch in tqdm(self.train_loader, leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(self.device), labels.to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(images) # this is logits\n",
        "        probs = torch.softmax(outputs, dim=-1)\n",
        "        log_probs = torch.log(probs)\n",
        "        loss = self.criterion(log_probs, labels) # you have to feed log_probs\n",
        "\n",
        "        acc = (torch.argmax(outputs, dim=-1) == labels.to(self.device)).sum() / len(labels)\n",
        "        # for torch.nn.NLLLoss\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.train_losses.append(loss.item())\n",
        "        self.train_accs.append(acc.item())\n",
        "        # don't try self.train_losses.append(loss)\n",
        "      # training step has ended\n",
        "      # we want to test our model on the validation set\n",
        "      valid_loss, valid_acc = self.validation()\n",
        "\n",
        "      # is this model the best? \n",
        "      # let's decide it based on valid_acc\n",
        "      if valid_acc > self.best_acc:\n",
        "        self.best_acc = valid_acc\n",
        "\n",
        "        # If it is the best model, save the model's weight'\n",
        "        models_parameters = self.model.state_dict()\n",
        "        print(f\"Saving best model at epoch {len(self.valid_accs)}, acc: {valid_acc}\")\n",
        "        torch.save(models_parameters, f'{self.model_name}_best.pt')\n",
        "\n",
        "      self.valid_losses.append(valid_loss)\n",
        "      self.valid_accs.append(valid_acc)\n",
        "\n",
        "    # Plot Accuracy curve\n",
        "    plt.plot(self.train_accs)\n",
        "    plt.plot(range(len(self.train_loader)-1, len(self.train_accs), len(self.train_loader)) ,self.valid_accs)\n",
        "    plt.title(\"Accuracy\")\n",
        "\n",
        "\n",
        "class Interpreter:\n",
        "  def __init__(self, model, test_loader):\n",
        "    self.model = model\n",
        "    self.loader = test_loader\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.criterion = nn.NLLLoss(reduction='none')\n",
        "\n",
        "    self.test_losses, self.test_preds = self.infer_loader()\n",
        "\n",
        "  def infer_loader(self):\n",
        "    self.model.to(self.device)\n",
        "    self.model.eval()\n",
        "    losses = torch.zeros(len(self.loader.dataset))\n",
        "    predicted_classes = torch.zeros(len(self.loader.dataset))\n",
        "    current_idx = 0\n",
        "    with torch.inference_mode():\n",
        "      for batch in self.loader:\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "        outputs = self.model(imgs)\n",
        "        log_probs = torch.log(torch.softmax(outputs, dim=-1))\n",
        "        loss = self.criterion(log_probs, labels)\n",
        "        losses[current_idx:current_idx+len(labels)] = loss.cpu()\n",
        "        predicted_classes[current_idx:current_idx+len(labels)] = torch.argmax(outputs, dim=-1).cpu()\n",
        "        current_idx += len(labels)\n",
        "    predicted_classes = predicted_classes.long().tolist()\n",
        "    return losses, predicted_classes\n",
        "\n",
        "\n",
        "  def plot_top_losses(self, topk=10):\n",
        "    top_losses, top_idx = torch.topk(self.test_losses, k=topk)\n",
        "    fig, axes = plt.subplots(topk, 1, figsize=(5, 5*topk))\n",
        "    class_names = self.loader.dataset.classes\n",
        "    for i in range(topk):\n",
        "      img, label = self.loader.dataset[top_idx[i]]\n",
        "      axes[i].imshow(tensor2pil(img))\n",
        "      axes[i].set_title(f\"True: {class_names[label]} /  Pred: {class_names[self.test_preds[top_idx[i]]]} / Loss: {top_losses[i]:.4f}, \")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "  def plot_confusion_matrix(self):\n",
        "    class_names = self.loader.dataset.classes\n",
        "    confusion_matrix = torch.zeros(len(class_names), len(class_names))\n",
        "    for i in range(len(self.loader.dataset)):\n",
        "      confusion_matrix[self.loader.dataset[i][1], self.test_preds[i]] += 1\n",
        "    confusion_matrix = confusion_matrix.numpy()\n",
        "    plt.figure(figsize = (10,7))\n",
        "    plt.imshow(confusion_matrix)\n",
        "    plt.xticks(range(len(class_names)), class_names, rotation=90)\n",
        "    plt.yticks(range(len(class_names)), class_names)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    for (x, y), value in np.ndenumerate(confusion_matrix):\n",
        "      plt.text(y, x, f\"{int(value)}\", va=\"center\", ha=\"center\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgnyp5YQDl4z"
      },
      "source": [
        "### Train a model with random initialization\n",
        "- The model's weight is initialized with random numbers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyWat72HDl4z"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(trainset.classes))\n",
        "trainer = Trainer(model, train_loader, test_loader, 'without_pretraining')\n",
        "trainer.train_by_number_of_epochs(num_epochs=15)\n",
        "save_fig_with_date(\"model_without_pretraining\")\n",
        "\n",
        "interpreter = Interpreter(model, test_loader)\n",
        "interpreter.plot_top_losses(topk=10)\n",
        "save_fig_with_date(\"model_without_pretraining_top_losses\")\n",
        "interpreter.plot_confusion_matrix()\n",
        "save_fig_with_date(\"model_without_pretraining_confusion_mat\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akw8HaGKC4Xy"
      },
      "outputs": [],
      "source": [
        "# you can also plot loss curve\n",
        "\n",
        "plt.plot(trainer.train_losses)\n",
        "plt.plot(range(len(trainer.train_loader)-1, len(trainer.train_accs), len(trainer.train_loader)) , trainer.valid_losses)\n",
        "plt.title(\"Loss\")\n",
        "plt.ylim([0,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B56VbjsGDl4z"
      },
      "source": [
        "### Train a model with pre-trained weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-Wux1A0LCxG"
      },
      "outputs": [],
      "source": [
        "# Use the same ResNet18 architecture but using pre-trained weights\n",
        "# as initial weights\n",
        "# The weight was trained with ImageNet 1K\n",
        "model = torchvision.models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(trainset.classes))\n",
        "trainer = Trainer(model, train_loader, test_loader, 'with_pretraining')\n",
        "trainer.train_by_number_of_epochs(num_epochs=15)\n",
        "save_fig_with_date(\"model_pretrained\")\n",
        "\n",
        "# the model was trained with 15 epochs\n",
        "# But the best validation accuracy was achieved in epoch 11 (12th epoch)\n",
        "\n",
        "interpreter = Interpreter(model, test_loader)\n",
        "interpreter.plot_top_losses(topk=10)\n",
        "save_fig_with_date(\"model_pretrained_top_losses\")\n",
        "interpreter.plot_confusion_matrix()\n",
        "save_fig_with_date(\"model_pretrained_confusion_mat\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwPuTBv-8pLu"
      },
      "source": [
        "#### Load Model\n",
        "- You can load the saved data by `torch.load()`\n",
        "- You can load the model's weight by `model.load_state_dict(state_dict)`\n",
        "- The code below will run `plot_top_losses` and `plot_confusion_matrix` with the model at the epoch with the best accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66QFiRKMDl4z"
      },
      "outputs": [],
      "source": [
        "saved_weight = torch.load('with_pretraining_best.pt')\n",
        "model.load_state_dict(saved_weight) # load trained weights parameters to the model\n",
        "\n",
        "interpreter = Interpreter(model, test_loader)\n",
        "interpreter.plot_top_losses(topk=10)\n",
        "save_fig_with_date(\"model_pretrained_best_epoch_top_losses\")\n",
        "interpreter.plot_confusion_matrix()\n",
        "save_fig_with_date(\"model_pretrained_best_epoch_confusion_mat\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iboSMkXAvRGu"
      },
      "source": [
        "## Problem 3: Clean your Dataset\n",
        "- The goal of data cleaning is to make sure that your dataset consists of images with specific characteristics you want.\n",
        "\n",
        "- Cell below is the modified version of `jmd_imagescraper.imagecleaner import display_image_cleaner`\n",
        "  - Once you run it, you can call `display_image_clenaer`\n",
        "  - *YOU HAVE TO RELOAD* the UI when you make different `display_image_cleaner`\n",
        "- If you click `delete` button, the image file will be moved to `DEL_DIR`, which is in default `images/deleted` \n",
        "- After the cleaning YOU HAVE TO SAVE YOUR RESULT by running the cell below.\n",
        "- TODO:\n",
        "  - Explain your criteria in cleaning certain examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYKVtXT1xgM"
      },
      "source": [
        "#### Cleaner code (run it without opening it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqQ3uhxLTNxl"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from pathlib import Path\n",
        "from PIL import Image as PImage\n",
        "from PIL import ImageDraw as PImageDraw\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from io import BytesIO\n",
        "\n",
        "##########################################################################################\n",
        "# globals & event handlers\n",
        "##########################################################################################\n",
        "ICLN_BATCH_SZ = 8\n",
        "\n",
        "# this may look nauseating and but creating new widgets is literally about 10x slower than \n",
        "# updating existing ones so the ui gets created once and updated forever more\n",
        "icln_base_path = None\n",
        "icln_folder = None\n",
        "icln_batches = None\n",
        "icln_pager = None\n",
        "icln_grid = None\n",
        "icln_empty_folder = None\n",
        "\n",
        "def delete_on_click(btn):\n",
        "  fn, img, batch, idx = btn.tag\n",
        "  img.value = icln_deleted_img() # display red 'deleted' cross\n",
        "  icln_batches[batch][idx] = \"\"  # so we know it's deleted as we page back & forth\n",
        "  btn.disabled = True\n",
        "  # try:    Path(fn).unlink()      # dbl-clicks result in us trying to delete twice\n",
        "  try: shutil.move(str(fn), DEL_DIR)\n",
        "  except Exception as e: print(e)\n",
        "\n",
        "def paging_on_click(btn):\n",
        "  folder, batch = btn.tag\n",
        "  icln_render_batch(folder, batch)\n",
        "\n",
        "def reload_on_click(btn):\n",
        "  icln_render_batch(icln_folder, 0, force_reload=True)\n",
        "\n",
        "def folder_on_change(change):\n",
        "  if(change[\"type\"] == \"change\" and change[\"name\"] == \"value\"):\n",
        "    icln_render_batch(change[\"new\"], 0)\n",
        "  \n",
        "##########################################################################################\n",
        "# UI creation\n",
        "##########################################################################################\n",
        "def icln_deleted_img():\n",
        "  # creates the red \"deleted\" placeholder cross and caches it\n",
        "  DELETED_IMG = \"deleted_img\"\n",
        "  \n",
        "  if(DELETED_IMG not in icln_deleted_img.__dict__):\n",
        "    img = PImage.new(\"RGB\",(150,150), color=\"white\")\n",
        "\n",
        "    draw = PImageDraw.Draw(img)\n",
        "    draw.line((5, 5, 140, 140), fill=\"red\", width=10)\n",
        "    draw.line((5, 140, 140, 5), fill=\"red\", width=10)\n",
        "    \n",
        "    bio = BytesIO()\n",
        "    img.save(bio, 'JPEG')\n",
        "    icln_deleted_img.__dict__[DELETED_IMG] = bio.getvalue()\n",
        "\n",
        "  return icln_deleted_img.__dict__[DELETED_IMG]\n",
        "\n",
        "def icln_create_widgets(batch_size):\n",
        "  # create the UI widgets\n",
        "  global icln_pager\n",
        "  global icln_grid\n",
        "  global icln_empty_folder\n",
        "\n",
        "  # image/delete button pairs\n",
        "  display_items = []\n",
        "  for i in range(batch_size):\n",
        "    img = widgets.Image()\n",
        "    img.layout.width=\"150px\"\n",
        "    btn = widgets.Button(description=\"Delete\")\n",
        "    btn.on_click(delete_on_click)\n",
        "    box = widgets.VBox(children=[img,btn])\n",
        "    box.layout.margin = \"5px\"\n",
        "    display_items.append(box)\n",
        "\n",
        "  # paging\n",
        "  btnFirst = widgets.Button(description=\"|<<\") \n",
        "  btnPrev = widgets.Button(description=\"<<\")\n",
        "  lblPage = widgets.Label(value=\"Page NNN of KKK\")\n",
        "  lblPage.layout = widgets.Layout(display=\"flex\", justify_content=\"center\", width=\"100px\")\n",
        "  btnNext = widgets.Button(description=\">>\")\n",
        "  btnLast = widgets.Button(description=\">>|\")\n",
        "  \n",
        "  pgbtns = [btnFirst, btnPrev, btnNext, btnLast]\n",
        "  for btn in pgbtns: btn.on_click(paging_on_click)\n",
        "  for btn in pgbtns: btn.layout.width = \"60px\"\n",
        "\n",
        "  # folder drop down\n",
        "  folders = [f.stem for f in icln_base_path.glob(\"*\") if (f.is_dir() and f.stem[0] != \".\")]\n",
        "  folders.sort()\n",
        "  rootfiles = [f for f in icln_base_path.glob(\"*.jpg\") if f.is_file()]\n",
        "  if(len(rootfiles) > 0): folders = [\"/\"] + folders\n",
        "  ddlFolder = widgets.Dropdown(options=folders, description=\"Folder: \")\n",
        "  ddlFolder.observe(folder_on_change)\n",
        "\n",
        "  # reload button\n",
        "  btnReload = widgets.Button(description=\"↻\")\n",
        "  btnReload.layout = widgets.Layout(width=\"40px\", margin=\"0px 0px 0px 10px\")\n",
        "  btnReload.on_click(reload_on_click)\n",
        "\n",
        "  # plug it all in and display\n",
        "  icln_pager = widgets.HBox(children=[btnFirst, btnPrev, lblPage, btnNext, btnLast, \n",
        "                                      ddlFolder, btnReload])  \n",
        "  icln_grid = widgets.GridBox(display_items, \n",
        "                              layout=widgets.Layout(grid_template_columns=\"repeat(4, 25%)\",\n",
        "                                                    margin=\"15px\"))\n",
        "  icln_empty_folder = widgets.HTML(value=\"<h2>No images left to display in this folder.</h2>\")\n",
        "  icln_empty_folder.layout.visibility = \"hidden\"\n",
        "\n",
        "  display(icln_pager)\n",
        "  display(icln_empty_folder)\n",
        "  display(icln_grid)\n",
        "  \n",
        "##########################################################################################\n",
        "# UI rendering\n",
        "##########################################################################################\n",
        "def icln_render_batch(folder, batch, force_reload=False):\n",
        "  global icln_folder\n",
        "  global icln_batches\n",
        "  global icln_pager\n",
        "  global icln_grid\n",
        "\n",
        "  if(folder == \"/\"): folder = \"\"\n",
        "  path = icln_base_path/folder\n",
        "\n",
        "  if((icln_folder != folder) or (force_reload)): \n",
        "    # get the files, split into batches  \n",
        "    files = list(path.glob(\"*.jpg\"))\n",
        "    icln_batches = [files[i:i + ICLN_BATCH_SZ] for i in range(0, len(files), ICLN_BATCH_SZ)]\n",
        "    icln_folder = folder\n",
        "\n",
        "    if(len(files) == 0):\n",
        "      # fail gracefully if they've deleted every image in this folder\n",
        "      icln_empty_folder.layout.visibility = \"visible\"\n",
        "      # icln_grid.layout.visibility = \"hidden\" <-- doesn't work :-@\n",
        "      for child in icln_grid.children: child.layout.visibility = \"hidden\"\n",
        "      btnFirst, btnPrev, lblPage, btnNext, btnLast,_,_ = icln_pager.children\n",
        "      lblPage.value = \"Page 0 of 0\"\n",
        "      for btn in [btnFirst, btnPrev, btnNext, btnLast]: btn.disabled = True\n",
        "      return\n",
        "    else:\n",
        "      icln_empty_folder.layout.visibility = \"hidden\"\n",
        "      icln_grid.layout.visibility = \"visible\"\n",
        "\n",
        "  # display the images\n",
        "  for i, fp in enumerate(icln_batches[batch]):\n",
        "    icln_grid.children[i].layout.visibility = \"visible\"\n",
        "    img = icln_grid.children[i].children[0]\n",
        "    btn = icln_grid.children[i].children[1]\n",
        "\n",
        "    if(fp == \"\"):\n",
        "      img.value = icln_deleted_img()\n",
        "      btn.disabled = True\n",
        "    else:\n",
        "      img.value = open(fp, \"rb\").read()\n",
        "      btn.tag = (fp, img, batch, i)\n",
        "      btn.disabled = False\n",
        "\n",
        "  if(len(icln_batches[batch]) < ICLN_BATCH_SZ):\n",
        "    # partial batch on the last page, hide the rest of the grid\n",
        "    for i in range(len(icln_batches[batch]), ICLN_BATCH_SZ):\n",
        "      icln_grid.children[i].layout.visibility = \"hidden\"\n",
        "    \n",
        "  # update the paging controls\n",
        "  btnFirst, btnPrev, lblPage, btnNext, btnLast,_,_ = icln_pager.children\n",
        "  btnFirst.tag = (folder, 0) \n",
        "  btnPrev.tag = (folder, max(0, batch-1)) \n",
        "  btnNext.tag = (folder, min(len(icln_batches)-1, batch+1)) \n",
        "  btnLast.tag = (folder, len(icln_batches)-1) \n",
        "  lblPage.value = \"Page {} of {}\".format(batch+1, len(icln_batches))\n",
        "  for btn in [btnFirst, btnPrev, btnNext, btnLast]: btn.disabled = btn.tag[1] == batch\n",
        "\n",
        "def display_image_cleaner(path):\n",
        "    '''Display the image cleaner widget for the given folder'''\n",
        "    global icln_base_path; icln_base_path = Path(path)\n",
        "    \n",
        "    icln_create_widgets(ICLN_BATCH_SZ)\n",
        "    _,_,_,_,_,ddlFolder,_ = icln_pager.children\n",
        "    icln_render_batch(ddlFolder.value, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkZlWp1j14Mf"
      },
      "source": [
        "#### Run `display_image_cleaner`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN_6GQV3z2As"
      },
      "outputs": [],
      "source": [
        "DEL_DIR.mkdir(exist_ok=True, parents=True)\n",
        "display_image_cleaner('images/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDV76afp1c2v"
      },
      "outputs": [],
      "source": [
        "# DO NOT FORGET TO CLICK RELOAD BUTTON on the top right of the UI \n",
        "display_image_cleaner('images/test') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyC2J_jn9Nep"
      },
      "source": [
        "- Don't Forget to save your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgW9IH5v9NME"
      },
      "outputs": [],
      "source": [
        "os.system(f\"zip -rq image_data_cleaned.zip {IMG_DIR}\") # Make zip file that contains images directory\n",
        "save_file(\"image_data_cleaned.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fum2E1igrY8_"
      },
      "source": [
        "# Problem 4. Train a new model with cleaned dataset\n",
        "- TODO:\n",
        "  - Explain whether the model's prediction has changed to what you have expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgsUM8m7Dl40"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainset = ImageSet(IMG_DIR/'train')\n",
        "testset = ImageSet(IMG_DIR/'test')\n",
        "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "model = torchvision.models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(trainset.classes))\n",
        "trainer = Trainer(model, train_loader, test_loader, 'after_cleaning')\n",
        "trainer.train_by_number_of_epochs(num_epochs=15)\n",
        "save_fig_with_date(\"model_after_cleaning\")\n",
        "model.load_state_dict(torch.load('after_cleaning_best.pt'))\n",
        "interpreter = Interpreter(model, test_loader)\n",
        "interpreter.plot_top_losses(topk=10)\n",
        "save_fig_with_date(\"model_after_cleaning_top_losses\")\n",
        "interpreter.plot_confusion_matrix()\n",
        "save_fig_with_date(\"model_after_cleaning_confusion_mat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRVv_itsDl40"
      },
      "source": [
        "# Problem 5 Test with Custom Image and Explain\n",
        "- Test your model with a custom input image\n",
        "  - Upload `jpg` files to `custom_images/`\n",
        "  - You can use drag and drop on Colab\n",
        "  - Test **at least 10 images**\n",
        "\n",
        "- TODO:\n",
        "  - Find failure cases and try to __explain__ why the model fails to classify it correctly\n",
        "  - In your opinion, what is the important pattern/characteristics that decides model's classification process? Why?\n",
        "  - It is important to test images that can provide you some clue, or give evidence for your hypothesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iVxQl24Dl40"
      },
      "outputs": [],
      "source": [
        "# YOU HAVE TO UPLOAD YOUR JPG IMAGE TO custom_images/ TO RUN THIS CELL\n",
        "custom_image_dir = Path(\"custom_images/\") # Path to directory containing custom images\n",
        "custom_image_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "custom_image_fns = list(custom_image_dir.glob(\"*.jpg\")) + list(custom_image_dir.glob(\"*.png\"))\n",
        "\n",
        "model.cpu()\n",
        "model.eval()\n",
        "plt.figure(figsize=(5, 5*len(custom_image_fns)))\n",
        "for i, fn in enumerate(custom_image_fns):\n",
        "  plt.subplot(len(custom_image_fns), 1, i+1)\n",
        "  img = Image.open(fn)\n",
        "  plt.imshow(img)\n",
        "  img_tensor = testset.transform(img)\n",
        "  pred = model(img_tensor.unsqueeze(0))\n",
        "  pred_class = trainset.classes[pred.argmax()]\n",
        "  plt.title(f\"Prediction: {pred_class} / Confidence: {pred.softmax(dim=-1).max():.3f}\")\n",
        "  plt.axis(\"off\")\n",
        "save_fig_with_date(\"custom_images_predictions\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-gYKVtXT1xgM"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
