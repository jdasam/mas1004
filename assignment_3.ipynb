{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/mas1004-2023/blob/main/assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa9wxy6-uXPY"
      },
      "source": [
        "# Coding Assignment 3\n",
        "- In this assignment, you have to train a simple matrix factorization model for the Small MovieLens dataset \n",
        "- The goal of this assignment is to have an experience with what kind of information a recommendation system learns from data\n",
        "- 84 pts for running the given code and analyzing the result just by changing some numbers\n",
        "- 16 pts for completing the given function\n",
        "- You have to submit a report and a code\n",
        "  1. A Report in free format (submit in PDF)\n",
        "    - Your setting about how you trained the model\n",
        "    - Your answer and explanation of 7 problems\n",
        "      - Including the Problems 6 and 7 (programming problems)\n",
        "    - Your submission would be evaluated mainly with the report\n",
        "    - Please include the screen capture of the table and visualization in your report\n",
        "  2. Code (submit in ipynb)\n",
        "- You don't have to use GPU for this assignment. I recommend you not to use hardware accelerator on Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJilvhV6imDY"
      },
      "source": [
        "# 0. Import Library and Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni3hUvDtHYN0"
      },
      "outputs": [],
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z8a8PMaHrau"
      },
      "source": [
        "### Import libraries and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jzyNviCHYN1"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class RatingSet:\n",
        "  def __init__(self, csv_path='ml-latest-small/ratings.csv'):\n",
        "    self.ratings = pd.read_csv(csv_path)\n",
        "\n",
        "    # how many unique users exist in this dataset\n",
        "    self.n_users = len(set(self.ratings['userId']))\n",
        "    self.n_movies = len(set(self.ratings['movieId']))\n",
        "\n",
        "    # list the every ids of included users\n",
        "    self.user_ids = list(set(self.ratings['userId']))\n",
        "    self.movie_ids = sorted(list(set(self.ratings['movieId'])))\n",
        "\n",
        "    # we have to find in which idx the given movieId exists in this dataset's movie ID\n",
        "    self.movie2idx = {id: idx for idx, id in enumerate(self.movie_ids)}\n",
        "    self.user2idx = {id: idx for idx, id in enumerate(self.user_ids)}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ratings) # number of ratings in the dataset\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    idx_row = self.ratings.iloc[idx]\n",
        "\n",
        "    user_id = self.user2idx[idx_row.userId]\n",
        "    movie_id = self.movie2idx[idx_row.movieId]\n",
        "    rating = idx_row.rating\n",
        "\n",
        "    return user_id, movie_id, torch.tensor(rating, dtype=torch.float32)\n",
        "\n",
        "class MatrixFactorizer(nn.Module):\n",
        "  def __init__(self, n_user, n_movie, n_factor):\n",
        "    super().__init__()\n",
        "\n",
        "    self.user_embedding = nn.Embedding(n_user, n_factor)\n",
        "    self.movie_embedding = nn.Embedding(n_movie, n_factor)\n",
        "\n",
        "    self.user_embedding.weight.data /= n_factor ** 0.5\n",
        "    self.movie_embedding.weight.data /= n_factor ** 0.5\n",
        "\n",
        "    self.scale = 5.5\n",
        "\n",
        "  def scaled_sigmoid(self, x):\n",
        "    return 1/(1+torch.exp(-x/self.scale)) * self.scale\n",
        "  \n",
        "  def forward(self, user_id, movie_id):\n",
        "    user_emb_vec = self.user_embedding(user_id)\n",
        "    movie_emb_vec = self.movie_embedding(movie_id)\n",
        "\n",
        "    dot_prod_result = torch.einsum('ij,ij->i', user_emb_vec, movie_emb_vec)\n",
        "    return self.scaled_sigmoid(dot_prod_result)\n",
        "\n",
        "\n",
        "\n",
        "class MatrixFactorizerWithBias(MatrixFactorizer):\n",
        "  def __init__(self, n_user, n_movie, n_factor):\n",
        "    super().__init__(n_user, n_movie, n_factor)\n",
        "    self.user_bias = nn.Embedding(n_user, 1)\n",
        "    self.movie_bias = nn.Embedding(n_movie, 1)\n",
        "    self.user_bias.weight.data = torch.zeros(n_user, 1)\n",
        "    self.movie_bias.weight.data = torch.zeros(n_movie, 1)\n",
        "  \n",
        "\n",
        "  def forward(self, user_id, movie_id):\n",
        "    user_emb_vec = self.user_embedding(user_id)\n",
        "    movie_emb_vec = self.movie_embedding(movie_id)\n",
        "\n",
        "    dot_prod_result = torch.einsum('ij,ij->i', user_emb_vec, movie_emb_vec)\n",
        "    dot_prod_result += self.user_bias(user_id)[:, 0] + self.movie_bias(movie_id)[:, 0]\n",
        "\n",
        "    return self.scaled_sigmoid(dot_prod_result)\n",
        "\n",
        "class Trainer:\n",
        "  def __init__(self, model, train_loader, valid_loader, model_name='movielens', device='cpu'):\n",
        "    self.model = model\n",
        "    self.train_loader = train_loader\n",
        "    self.valid_loader = valid_loader\n",
        "    self.device = device\n",
        "    self.model.to(self.device)\n",
        "    self.criterion = nn.MSELoss()\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "    self.acc_threshold = 0.5\n",
        "    self.best_loss = torch.inf\n",
        "    self.best_acc = 0.0\n",
        "    self.train_losses = []\n",
        "    self.valid_losses = []\n",
        "    self.train_accs = []\n",
        "    self.valid_accs = []\n",
        "    self.model_name = model_name\n",
        "\n",
        "  def validation(self):\n",
        "    self.model.eval() # change the model from train mode to evaluation mode\n",
        "    # Some models work in different ways based on whtehter it is on training step\n",
        "    # or on inference step\n",
        "\n",
        "    # In validation step, you don't have to calculate the gradient\n",
        "    # with torch.no_grad():\n",
        "\n",
        "    current_loss = 0\n",
        "    num_total_correct_pred = 0\n",
        "    with torch.inference_mode(): # every torch computation under this indent\n",
        "    # will be run without calculating the gradient or computation history\n",
        "      for batch in self.valid_loader:\n",
        "        user_ids, movie_ids, ratings = batch\n",
        "        user_ids, movie_ids, ratings = user_ids.to(self.device), movie_ids.to(self.device), ratings.to(self.device)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(user_ids, movie_ids) \n",
        "\n",
        "        loss = self.criterion(outputs, ratings) # you have to feed log_probs\n",
        "\n",
        "        num_acc_pred = (torch.abs(outputs - ratings) < self.acc_threshold).sum()\n",
        "\n",
        "        num_total_correct_pred += num_acc_pred.item()\n",
        "        # in validation stage, we don't care about single batch's loss\n",
        "        # we want to see the result for total images of validation set\n",
        "\n",
        "        current_loss += loss.item() * len(ratings)\n",
        "        # instead of adding the mean loss, we add sum of loss\n",
        "        # because the batch size can be different\n",
        "    mean_loss = current_loss / len(self.valid_loader.dataset)\n",
        "    mean_acc = num_total_correct_pred / len(self.valid_loader.dataset) # number of total datasample in the validation loader\n",
        "    return mean_loss, mean_acc\n",
        "    # return {'loss': mean_loss, 'acc': mean_acc}\n",
        "\n",
        "\n",
        "\n",
        "  def train_by_number_of_epochs(self, num_epochs):\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "      self.model.train()\n",
        "      for batch in tqdm(self.train_loader, leave=False):\n",
        "        user_ids, movie_ids, ratings = batch\n",
        "        user_ids, movie_ids, ratings = user_ids.to(self.device), movie_ids.to(self.device), ratings.to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(user_ids, movie_ids) \n",
        "\n",
        "        loss = self.criterion(outputs, ratings) # you have to feed log_probs\n",
        "\n",
        "        acc = (torch.abs(outputs - ratings) < self.acc_threshold).sum() / len(ratings)\n",
        "        # for torch.nn.NLLLoss\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.train_losses.append(loss.item())\n",
        "        self.train_accs.append(acc.item())\n",
        "        # don't try self.train_losses.append(loss)\n",
        "        # because loss is a torch.tensor object\n",
        "        \n",
        "      # training step has ended\n",
        "      # we want to test our model on the validation set\n",
        "      valid_loss, valid_acc = self.validation()\n",
        "\n",
        "      # is this model the best? \n",
        "      # let's decide it based on valid_acc\n",
        "      if valid_acc > self.best_acc:\n",
        "        self.best_acc = valid_acc\n",
        "\n",
        "        # If it is the best model, save the model's weight'\n",
        "        models_parameters = self.model.state_dict()\n",
        "        print(f\"Saving best model at epoch {len(self.valid_accs)}, acc: {valid_acc}\")\n",
        "        torch.save(models_parameters, f'{self.model_name}_best.pt')\n",
        "\n",
        "      self.valid_losses.append(valid_loss)\n",
        "      self.valid_accs.append(valid_acc)\n",
        "\n",
        "    # Plot Accuracy curve\n",
        "    plt.plot(self.train_accs)\n",
        "    plt.plot(range(len(self.train_loader)-1, len(self.train_accs), len(self.train_loader)) ,self.valid_accs)\n",
        "    plt.title(\"Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naxjqnVRHYN2"
      },
      "source": [
        "## Prepare Data Split and DataLoader "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMFog-xcHYN2"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
        "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "\n",
        "movies = movies[movies['movieId'].isin(ratings['movieId'])]\n",
        "movies.reset_index(drop=True, inplace=True)\n",
        "movies['title'].to_csv(\"list_of_movie_titles.csv\")\n",
        "\n",
        "dataset = RatingSet()\n",
        "num_train = int(len(dataset)*0.9)\n",
        "num_valid = int(len(dataset)*0.05)\n",
        "num_test = len(dataset) - num_train - num_valid\n",
        "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, \n",
        "                                              [num_train, num_valid, num_test],\n",
        "                                               generator=torch.Generator().manual_seed(0))\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=512, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=512, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO2h--e8i98K"
      },
      "source": [
        "## Problem 0. Train Embeddings\n",
        "- You can train your model by selecting proper `n_factors` and `n_epoch`\n",
        "- **IMPORTANT about Report:** You have to explain your hyperparameters for training the model\n",
        "  - `n_factors`\n",
        "  - `n_epoch`\n",
        "  - Why did you choose those specific values?\n",
        "- **You have to select proper n_factors and n_epoch**\n",
        "  - If you choose reasonable hyperparameters, you will get more than **0.4 validation accuracy**\n",
        "- For default value, you can use `n_factors=50` and `n_epoch=7`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_r7XBGskW2k"
      },
      "outputs": [],
      "source": [
        "# TODO: Select Proper Hyperparameters, n_factors and n_epoch\n",
        "n_factors = 50\n",
        "n_epoch = 7\n",
        "\n",
        "model = MatrixFactorizerWithBias(dataset.n_users, dataset.n_movies, n_factors)\n",
        "trainer = Trainer(model, train_loader, valid_loader, device='cuda')\n",
        "trainer.train_by_number_of_epochs(n_epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC_nWYPZu6b0"
      },
      "source": [
        "### Select the model based on validation loss\n",
        "- The training code saves model parameters for every epoch\n",
        "- Based on your criteria, you can select the model by epoch\n",
        "  - If you want to load the Epoch 10 version, run `model.load_state_dict(model_states[10])`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtBgakBQwcc_"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('movielens_best.pt'))\n",
        "movie_embs = model.movie_embedding.weight.detach().cpu()\n",
        "movie_bias = model.movie_bias.weight.detach().cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cofoanuv02-"
      },
      "source": [
        "## Problem 1: Analyze Bias of Movie Embedding: Why do we use Bias?\n",
        "- Explain why some films have high bias and some films have low bias\n",
        "  - Explain the commonality between films with high bias\n",
        "  - Explain the commonality between films with low bias\n",
        "  - Explain why is using bias helps to make a recommendation system\n",
        "- Following code will show the title of movie by descending order of bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwTWyJYP52wp"
      },
      "outputs": [],
      "source": [
        "indices = torch.argsort(movie_bias.squeeze(), descending=True)\n",
        "indices = indices.tolist()\n",
        "pd.set_option('display.min_rows', 20) # you can set number of print rows by this line\n",
        "pd.DataFrame({\"title\": list(movies['title'].iloc[indices]), \"bias\": movie_bias[indices].squeeze().tolist()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaUKaasR26pj"
      },
      "source": [
        "## Problem 2: Similarity Search\n",
        "- Try to find the most similar movies and least similar movies for a given movie\n",
        "- Explain whether the searched result makes sense to you or not\n",
        "- In report, **explain at least 3 examples of your choice**\n",
        "- The following code will print out the movies based on their similarities to a selected movie\n",
        "  - Similarities are calculated based on movie embeddings with cosine similarity\n",
        "- You can search the id of movies from `list_of_movie_titles.csv` that is uploaded in Cyber Campus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgZ9scgWxbES"
      },
      "outputs": [],
      "source": [
        "def get_cosine_sim(emb, embs):\n",
        "  with torch.no_grad():\n",
        "    return torch.sum(emb * embs, dim=1) / (torch.sum(emb**2) * torch.sum(embs**2, dim=-1)) ** 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKM6cu2P28it"
      },
      "outputs": [],
      "source": [
        "movie_embs = model.movie_embedding.weight.cpu()\n",
        "sel_movie_id = 5682 # Select the desired movie ID from list_of_movie_titles.csv\n",
        "\n",
        "sims = get_cosine_sim(movie_embs[sel_movie_id], movie_embs)\n",
        "sims[sel_movie_id]=0\n",
        "_, indices = torch.sort(sims, descending=True)\n",
        "indices = indices.tolist()\n",
        "print(f\"Titles of selected movie_id is: {movies.iloc[sel_movie_id]['title']}\")\n",
        "pd.DataFrame({\"title\":list(movies['title'].iloc[indices]), \"genre\":list(movies['genres'].iloc[indices]), \"similarity\": sims[indices].tolist()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCp2Ue5xqhmK"
      },
      "source": [
        "## Problem 3: Embedding Visualization\n",
        "- **Navigate through the visualization and discover interesting informations from the embeddings**\n",
        "  - For examples,\n",
        "    - Which movies are making a cluster?\n",
        "      - Are the movies in a cluster looks similar to you?\n",
        "    - Which movies are located far away?\n",
        "- **Explain how your model could learn such similarities based only on the user's ratings**\n",
        "- You can use both 2D plot and 3D plot, or just select one to work with based on your preference\n",
        "  - I recommend you to use 2D plot for discovering local cluster, and 3D plot for global view\n",
        "\n",
        "- **You have to attach the screen capture of each cluster**\n",
        "- The code below will make UMAP transformation of the given trained movie embeddings\n",
        "  - Regardless of what factor you selected for the matrix factorization, UMAP can reduce the dimension of embedding to 2D or 3D\n",
        "  - UMAP is one of machine learning algorithms for reducing data dimension, and it is a very good tool for making data visualization\n",
        "  - During the dimension reduction, UMAP tries to the preserve local neighbor distance and also the global distance\n",
        "  - Movies with similar embeddings will be located closely to each other in the UMAP embeddings\n",
        "  - For the detailed explanation about what is UMAP, please refer this [YouTube video](https://youtu.be/6BPl81wGGP8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJU3PVESURq8"
      },
      "source": [
        "### 0: Install and Import Library, Setup pre-defined functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqLFzelo3fFl"
      },
      "outputs": [],
      "source": [
        "!pip install -q umap-learn\n",
        "!pip install -Uq plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qQcl3XhSqgE2",
        "outputId": "fdd46490-5cc5-40bf-e1dd-b72327a07d30"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import umap\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "def get_umap_embedding(embedding, n_reduced_dimension=2, n_neighbors=15):\n",
        "  reducer = umap.UMAP(n_components=n_reduced_dimension, n_neighbors=n_neighbors)\n",
        "  umap_emb = reducer.fit_transform(embedding)\n",
        "  return umap_emb\n",
        "\n",
        "def make_scatter3d(emb, label):\n",
        "  trace = go.Scatter3d(\n",
        "    x=emb[:,0],  \n",
        "    y=emb[:,1],  \n",
        "    z=emb[:,2], \n",
        "    mode='markers',\n",
        "    marker={\n",
        "        'size': 2,\n",
        "        'opacity': 0.5,\n",
        "    },\n",
        "    text = label,\n",
        "  )\n",
        "  return trace\n",
        "\n",
        "def make_3d_plot_with_pyplot(embs, labels, highlighted_titles):\n",
        "  highlighted_indices = [labels.index(title) if title in labels else 0 for title in highlighted_titles]\n",
        "  layout = go.Layout(\n",
        "      margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
        "      scene=dict(\n",
        "          annotations = [dict(x=embs[i,0], y=embs[i,1], z=embs[i,2],text=labels[i]) for i in highlighted_indices ]\n",
        "      )\n",
        "  )\n",
        "  data = make_scatter3d(embs,labels)\n",
        "  plot_figure = go.Figure(data=data, layout=layout)\n",
        "  plot_figure.update_traces(textposition='top center')\n",
        "  plot_figure.show(renderer='colab')\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjMs5DBzUa6n"
      },
      "source": [
        "### 3-1 Make Embeddings\n",
        "- `n_neighbors` is a hyperparameter of UMAP. If you use larger n_neighbors, UMAP will consider more neighbors for each item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcKc0Sj4qupz"
      },
      "outputs": [],
      "source": [
        "movie_embs_np = movie_embs.detach().numpy()\n",
        "\n",
        "embs_2d = get_umap_embedding(movie_embs_np, n_reduced_dimension=2, n_neighbors=15)\n",
        "embs_3d = get_umap_embedding(movie_embs_np, n_reduced_dimension=3, n_neighbors=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcjkGv0r-soK"
      },
      "source": [
        "- Following code will make simple static PLT plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIXla5tRUH-8"
      },
      "outputs": [],
      "source": [
        "plt.scatter(embs_2d[:,0], embs_2d[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87uUQ_OMHcus"
      },
      "source": [
        "- Following code will make interactive 3D plot of UMAP embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtHP8lBzHcXL"
      },
      "outputs": [],
      "source": [
        "make_3d_plot_with_pyplot(embs_3d, list(movies['title']), highlighted_titles=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxdyY5hMpsE_"
      },
      "source": [
        "#### Filter Movies based on Movie Ratings\n",
        "- Are you tired of looking through the movie title of that you've never heard of?\n",
        "- You can filter the embeddings based on movie ratings, so that you can select embeddings with number of ratings\n",
        "  - Frequently rated movies can be regarded as famous movies\n",
        "  - You can select the number of plots by changing `k=n_movies`\n",
        "  - e.g. `k=100` to select only top 100 movies in number of ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5Z4C3FNqb09"
      },
      "outputs": [],
      "source": [
        "def get_mean_movie_ratings(ratings, movie_ids):\n",
        "  scores = [ratings[ratings['movieId']==id]['rating'].mean() if len(ratings[ratings['movieId']==id])>0 else 0  for id in movie_ids]\n",
        "  return scores\n",
        "\n",
        "def get_number_movie_ratings(ratings, movie_ids):\n",
        "  scores = [(ratings['movieId']==id).sum()  for id in movie_ids]\n",
        "  return scores\n",
        "# movie_ratings_in_order_of_title = get_mean_movie_ratings(ratings, list(dls.classes['title']))\n",
        "num_movie_ratings_in_order_of_title = get_number_movie_ratings(ratings, list(movies['movieId']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kEB9hF8p85f"
      },
      "outputs": [],
      "source": [
        "k = 100\n",
        "# k = n_movies # select desired number of movies\n",
        "indices_of_top_k_movies =  np.asarray(num_movie_ratings_in_order_of_title).argsort()[::-1][:k]\n",
        "movie_embs_filtered = movie_embs_np[indices_of_top_k_movies]\n",
        "\n",
        "filtered_2d_embs = get_umap_embedding(movie_embs_filtered, n_reduced_dimension=2, n_neighbors=15)\n",
        "filtered_3d_embs = get_umap_embedding(movie_embs_filtered, n_reduced_dimension=3, n_neighbors=15)\n",
        "filtered_titles = movies.iloc[indices_of_top_k_movies]['title']\n",
        "filtered_titles.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVmaBemxjPiw"
      },
      "source": [
        "#### 2D plot\n",
        "- Navigate the 2D UMAP plot to find interesting clusters of movies\n",
        "- You can zoom and navigate through the interface on top right of the plotly figure, as below\n",
        "\n",
        "![image.png](https://github.com/jdasam/mas1004-2023/blob/main/figs/assign_3_figure1.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVys3pOlVbV5"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(x=filtered_2d_embs[:,0], y=filtered_2d_embs[:,1], text=list(filtered_titles))\n",
        "fig.show(renderer=\"colab\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWqoZ0ykiKdc"
      },
      "source": [
        "#### 3D Plot\n",
        "- You can rotate the camera with left click drag\n",
        "- You can pan the camera with right click drag\n",
        "- You can add 3D title annotations by add titles in `highlighted_movie_titles`\n",
        "  - e.g. `highlighted_movie_titles = [\"Titanic (1997)\", \"Back to the Future (1985)\"]`\n",
        "  - You have to exactly match the title name\n",
        "    - including year, and upper cases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQwONvc1rOE7"
      },
      "outputs": [],
      "source": [
        "highlighted_movie_titles = [\"Titanic (1997)\", \"Back to the Future (1985)\", \"Spider-Man (2002)\", \"Batman Begins (2005)\"]\n",
        "make_3d_plot_with_pyplot(filtered_3d_embs,list(filtered_titles), highlighted_titles=highlighted_movie_titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-c_hIbjyT8D"
      },
      "source": [
        "## Problem 4: Interpreting Dimension\n",
        "- The trained embedding space has several dimensions\n",
        "- Can you explain what kind of characteristics does each dimension represents?\n",
        "  - For a selcted dimension, try to figure out what is the commonalities between movies with high value in that dimension, and between movies with low value in that dimension\n",
        "  - Give your explanation or hypothesis that can explain one of the dimensions \n",
        "    - e.g. \"This dimension seems that it represents 'Casting-Top-Male-Star', because movies with famous male actor had high value\"\n",
        "    - e.g. \"This dimension seems that it represents 'Horror film', because horror movies got the high values and movies for children had low values\"\n",
        "  - There is no answer to this question. The trained result can be different based on the number of factors and random seed for the random initialization\n",
        "    - You don't have to explain all the dimension.\n",
        "    - Your hypothesis doesn't need to be perfect, that can explains entire tendency\n",
        "- **You HAVE TO attach the screen capture of top and bottom 10 movies of the selected dimension on the report**\n",
        "- You can set the print options with `pd.set_option('display.min_rows', 20)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGUJa4GHxSaB"
      },
      "outputs": [],
      "source": [
        "selected_dim_idx = 0\n",
        "movie_embs_tensor = torch.tensor(movie_embs)\n",
        "_, indices = torch.sort(movie_embs_tensor[:,selected_dim_idx], descending=True)\n",
        "indices = indices.tolist()\n",
        "pd.DataFrame({\"title\": list(movies.iloc[indices]['title']), \"Genres\": list(movies.iloc[indices]['genres']),  \"Value\": movie_embs[indices, selected_dim_idx].tolist()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL2yqZptpyOH"
      },
      "source": [
        "## Problem 5: Calculate Classification Accuracy (8 pts)\n",
        "- MSE Loss does not tell how many of your estimations were correct or not\n",
        "- Complete a code that can calculate the accuracy\n",
        "  - Let's define that the prediction is accurate if and only if the rounded value of estimation matches with the ground-truth score\n",
        "    - e.g.: If the estimated rating is 2.4 and the ground-truth rating is 2, it is considered as an accurate (correct) estimation\n",
        "    - e.g.: If the estimated rating is 3.6 and the ground-truth rating is 3, it is considered as an inaccurate (wrong) estimation\n",
        "  - For given validation data samples, the `get_accuracy(pred, target)` has to count the number of correct estimation then divide by total number of data sample\n",
        "\n",
        "- use `atensor.item()` to convert a tensor with single value to a float\n",
        "- Attach the screen capture of the code in your report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TjGtHwjpxws"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(pred,target):\n",
        "  '''\n",
        "  pred (torch.Tensor): Estimated ratings of data samples. Shape of [n,1], where n is number of data samples\n",
        "  target (torch.Tensor): Ground-truth ratings of data samples. Shaoe of [n,1], where n is number of data samples\n",
        "\n",
        "  The order of data sample for pred and target is same.\n",
        "\n",
        "  output (float): Number of correct estimations divided by number of data samples\n",
        "\n",
        "  Hint: You can get the round value for each element of Tensor by torch.round(atensor)\n",
        "  '''\n",
        "  # TODO: Complete this function\n",
        "  return\n",
        "\n",
        "'''\n",
        "You don't have to change the code below\n",
        "'''\n",
        "\n",
        "dummy_estimation = torch.Tensor([[2.532], [1.672], [3.741], [4.512], [2.701] ])\n",
        "dummy_target = torch.Tensor([[2], [1], [4], [5], [2] ])\n",
        "accuracy = get_accuracy(dummy_estimation, dummy_target)\n",
        "\n",
        "print(f\"The accuracy is {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8D27JaxqZf"
      },
      "source": [
        "## Problem 6: Estimate the ratings for a user and a movie (8 pts)\n",
        "- Using the embeddings and biases of user and movie, calculate the estimated rating of the user for the movie\n",
        "  - Definition of dot product (from [here](https://en.wikipedia.org/wiki/Dot_product))\n",
        "  - ![dot_product](https://github.com/jdasam/mas1004-2023/blob/main/figs/assingment_3_dot_product.png?raw=true)\n",
        "  - Rating can be estimated by dot product value of user and item embeddings added with user's bias and item's bias\n",
        "- Attach the screen capture of the code in your report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSQ04OT6xnq1"
      },
      "outputs": [],
      "source": [
        "def estimates_rating(user_embedding, movie_embedding, user_bias, movie_bias):\n",
        "  '''\n",
        "  user_embedding (torch.Tensor): Trained embeddings for a user, in shape of [n_factors]\n",
        "  user_embedding (torch.Tensor): Trained embeddings for a movie, in shape of [n_factors]\n",
        "  user_bias (torch.Tensor): Trained bias for a user, in shape of [1]\n",
        "  movie_bias (torch.Tensor): Trained bias for a user, in shape of [1]\n",
        "\n",
        "  output (torch.Tensor): Estimated score of the user for the movie\n",
        "  '''\n",
        "  # TODO: Complete this function\n",
        "  # You don't have to consider sigmoid_range for this problem\n",
        "  # The scaling function will be applied after this function \n",
        "  return\n",
        "\n",
        "selected_user_index = 0\n",
        "selected_movie_index = 0\n",
        "\n",
        "\n",
        "'''\n",
        "You don't have to change the code below\n",
        "'''\n",
        "\n",
        "selected_user_emb = model.user_embedding.weight[selected_user_index]\n",
        "selected_movie_emb = model.movie_embedding.weight[selected_movie_index]\n",
        "selected_user_bias = model.user_bias.weight[selected_user_index]\n",
        "selected_movie_bias = model.movie_bias.weight[selected_movie_index]\n",
        "\n",
        "estimated_rating = estimates_rating(selected_user_emb, selected_movie_emb, selected_user_bias, selected_movie_bias)\n",
        "estimated_rating = model.scaled_sigmoid(estimated_rating).item()\n",
        "\n",
        "print(f\"Estimated rating of user {selected_user_index} for movie {movies.iloc[selected_movie_index]['title']} is {estimated_rating}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UJU3PVESURq8"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
