{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/mas1004/blob/2024/live_coding/2_function_approximation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErJV9S8NChuq"
      },
      "source": [
        "# Function Approximation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K89yBL1BqnI"
      },
      "source": [
        "## A. Regression with One Variable\n",
        "- Regression:\n",
        "  - Process of training a model to predict a **continuous** numerical output based on one or more input features.\n",
        "  - e.g.: Predicts the child's height based on the parent's height.\n",
        "  - Why is it named \"regression\"?:\n",
        "    - The term was first used by Sir Francis Galton, a British statistician and cousin of Charles Darwin, in the late 19th century. Galton was studying the relationship between heights of parents and their children. He observed that although tall parents often had tall children, the children's heights tended to \"regress\" towards the average or mean height of the population. Similarly, children of short parents were often short but their heights still regressed towards the average."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6zfXa2tChus"
      },
      "source": [
        "- Let's make function that works as f(x) = ax+b\n",
        "    -  In this cell, we will create a function that follows the linear equation format f(x) = ax + b. This function will take an input x and return value that is the result of the equation. The variables a and b are coefficients that we will define. The variable a is the slope of the line and b is the y-intercept. This function will help us understand the concept of function approximation in the context of regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HkqNYWTBqnJ",
        "outputId": "967eca9e-744d-420d-d393-4be5a4eaecbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.5"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's make function that works as f(x) = ax+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbcrAnKGDGtE",
        "outputId": "977faf6f-c797-48f9-b880-3b987cd08e14"
      },
      "outputs": [],
      "source": [
        "# Let's plot this function\n",
        "# First, let's make many x candidates\n",
        "# from -5 to 5, with 500 total x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVatQ4InEUQ0",
        "outputId": "b2619056-e167-4e33-c1ff-156db83aa96a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 numbers: [-9.5, -9.46, -9.42, -9.38, -9.34, -9.3, -9.26, -9.22, -9.18, -9.14]\n",
            "Last 10 numbers: [10.14, 10.18, 10.22, 10.26, 10.3, 10.34, 10.38, 10.42, 10.46, 10.5]\n"
          ]
        }
      ],
      "source": [
        "# Now, let's make y\n",
        "# y = f(x)\n",
        "\n",
        "# Using for loop\n",
        "ys = []\n",
        "\n",
        "# Using list comprehension\n",
        "ys = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQDsS3vnEjRu",
        "outputId": "47a41d71-9b97-49ef-a44a-4fa1f95011f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(501, 501)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the length of xs and ys are equal\n",
        "# The item of xs and ys are 1:1 mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv58AK2kEmun",
        "outputId": "90633b5a-6a2b-4287-9930-5fb70a7423cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ys[23] = my_function(xs[23])\n",
            "xs[23]: -4.54, ys[23]: -8.58, my_function(xs[23]): -8.58\n"
          ]
        }
      ],
      "source": [
        "# We can check that i-th value of xs and ys are 1:1 mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "IGch1r6HE2sl",
        "outputId": "f774003a-186e-471e-b8c1-476cf4508771"
      },
      "outputs": [],
      "source": [
        "# Let's plot this function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JmJxSsBSFKzo"
      },
      "outputs": [],
      "source": [
        "# Let's add some noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "4uuc-dMbFKsx",
        "outputId": "2324d405-3b73-4128-983d-ef1c0d7d38b7"
      },
      "outputs": [],
      "source": [
        "# plot again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-ULt92mChuv"
      },
      "source": [
        "##### (Extra) Short Explanation about Random Number Generator\n",
        "- Random number generator is a function that generates a sequence of numbers that seem to occur in random order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU_PHZ1-F7Qg",
        "outputId": "5c070cbc-6c62-4bbb-abf7-c6b188716801"
      },
      "outputs": [],
      "source": [
        "# random is not actually complete random\n",
        "# usually computers uses pseudo-random\n",
        "\n",
        "# random.random() in fact has its destiny. It will always return same value\n",
        "# if the seed is the same\n",
        "\n",
        "# No matter how many times you run this code, it will always return same value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHeOBhEMChuw"
      },
      "source": [
        "### 1) Guess Regression manually\n",
        "- Since we know the function f(x) = ax + b, we can guess the value of a and b.\n",
        "- If we select correct a and b, the line will be the best fit line for the data.\n",
        "    - What machine learning does is to find the best a and b automatically.\n",
        "    - But here, we will find the best a and b manually, so that we can understand the concept of machine learning better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "PQMSHCf0HhCc",
        "outputId": "717fdd84-1398-466d-abf4-72b968f9b212"
      },
      "outputs": [],
      "source": [
        "# Let's suppose we try guessing a and b manually\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvd3Q0rvChuw"
      },
      "source": [
        "#### 1-1) Calculating Error\n",
        "- How can we calculates how good or bad our estimation is?\n",
        "    - We can calculate the error between the actual value and the predicted value.\n",
        "        - There are many ways to calculate the error.\n",
        "            - For example, we can calculate the absolute value of the difference between the actual value and the predicted value.\n",
        "            - Or we can calculate the square of the difference between the actual value and the predicted value.\n",
        "    - We call this error value as **loss**.\n",
        "        - Sometimes, we call this error as **cost**.\n",
        "    - The function that calculates the loss is called **loss function**.\n",
        "        - Sometimes, we call this loss function as **cost function** or **objective function**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWNEMo0DIh6B",
        "outputId": "e7f88074-fa94-46c1-b77c-5c6da9d941b9"
      },
      "outputs": [],
      "source": [
        "def cal_error(pred, target):\n",
        "  return abs(pred-target) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBRLWcy9J6fH",
        "outputId": "7a36988f-12a1-496d-e6a1-c7f8b73b2ce9"
      },
      "outputs": [],
      "source": [
        "# compare every value in y_noise and estimation\n",
        "# we have to compare values in the same idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U_wVFZjK8j2",
        "outputId": "84f28598-b6c5-4944-d4d0-3846c4553681"
      },
      "outputs": [],
      "source": [
        "# change a and b to get better estimation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuLMallPoCM"
      },
      "source": [
        "#### (Extra) calculate gradient\n",
        "- How can we calculate the slope (gradient) of each parameter?\n",
        "  - We can calculate the gradient of the loss function with respect to each parameter.\n",
        "  - One brutal way to calculate the gradient is to calculate the loss function for each parameter and see how the loss function changes when we change the parameter a little bit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO9xazcLPsSC",
        "outputId": "db7b8ef6-1e84-4c3e-f081-b72e2db92b0f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMEZ70i7YiCc"
      },
      "source": [
        "##### (Extra) Naming Convention\n",
        "- CamelCase\n",
        "  - uses upper letter to distinguish words\n",
        "    - MyModelFunction\n",
        "    - myModelFunction\n",
        "- snake_case\n",
        "  - uses underbar\n",
        "    - my_model_function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSExqxKBChux"
      },
      "source": [
        "### 2. Using Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im6dyEahChux"
      },
      "source": [
        "#### 2-1) Define the function\n",
        "- We want to design more complex function that is not linear.\n",
        "    - And we will try approximating the function using neural network.\n",
        "\n",
        "- To do this, we will practice with ``class``\n",
        "    - ``class`` is a template for creating objects.\n",
        "        - It has attributes and methods.\n",
        "            - Attributes are variables that store data.\n",
        "            - Methods are functions that are defined inside the class.\n",
        "        - We can create an object from a class.\n",
        "            - We call this process as **instantiation**.\n",
        "            - The object that is created from a class is called **instance**.\n",
        "        - We can access the attributes and methods of an object using dot notation.\n",
        "            - ``object.attribute``\n",
        "            - ``object.method()``\n",
        "        - We can define a class using ``class`` keyword.\n",
        "            - ``class ClassName:``\n",
        "        - We can define a method using ``def`` keyword.\n",
        "            - ``def method_name(self, arguments):``\n",
        "            - Every method should have ``self`` as the first argument.\n",
        "                - ``self`` is a reference to the current instance of the class.\n",
        "                - We can access the attributes and methods of the class using ``self``.\n",
        "                - ``self`` is not a keyword. You can use any word instead of ``self``.\n",
        "                    - But it is a convention to use ``self``.\n",
        "            - There are special methods that are defined using double underscore.\n",
        "                - ``__init__`` is a special method that is called when an instance of a class is created.\n",
        "                    - We call this process as **instantiation**.\n",
        "                    - ``class_instance = ClassName(arguments)``\n",
        "                - ``__call__`` is a special method that is called when an instance of a class is called.\n",
        "                    - ``class_instance(arguments)``\n",
        "                \n",
        "\n",
        "        - We can define an attribute using ``self``.\n",
        "            - ``self.attribute_name = value``\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLKychJdChuy"
      },
      "source": [
        "#### 2-2) Making Artificial Neuron\n",
        "An artificial neuron is a mathematical function designed to model the behavior of biological neurons. It serves as a fundamental building block of neural networks in machine learning.\n",
        "\n",
        "##### Basic Components\n",
        "- Input: Receives various forms of information (or data) that the neural network will learn from.\n",
        "- Weights: These are parameters that transform input data within the neuron's internal function.\n",
        "- Bias: An additional parameter to shift the activation function.\n",
        "- Activation Function: This function processes the incoming information, and depending on its output, the artificial neuron activates or not.\n",
        "\n",
        "$\\text{Output} = \\text{Activation Function}(\\sum^n_{i=1}(\\text{Input}[i] \\times \\text{Weight}[i]) + \\text{Bias})$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZqLCB39Chuy"
      },
      "source": [
        "#### 2-4) Implementing following digaram in Python\n",
        "- Ignoring the bias and activation now\n",
        "![data_ai_figure.jpg](https://github.com/jdasam/mas1004-2023/blob/main/live_coding/data_ai_figure.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKK-iRmdChuy"
      },
      "source": [
        "#### 2-5) Implementing it as a matrix and layer\n",
        "- Using ``torch`` library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKDxWQ4hChvA"
      },
      "source": [
        "#### 2-6) Make two layers model for function approximation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNFq6cItChvA"
      },
      "source": [
        "#### 2-7) Combination of Linear Operation\n",
        "- Let's suppose the first layer of the neural network takes 1-dim input and has 4 neurons\n",
        "    - Each neuron has 1 weight and 1 bias\n",
        "    - weights = $[w_1, w_2, w_3, w_4]$\n",
        "    - bias = $[b_1, b_2, b_3, b_4]$\n",
        "    - for input $x$, the result is\n",
        "        - $[w_1 x + b_1, w_2 x + b_2, w_3 x + b_3, w_4 x + b_4]$\n",
        "        - or, we can notate them using $o_n$, so that\n",
        "            - $o_n = w_n x + b_n$\n",
        "            - $o_1 = w_1 x + b_1$\n",
        "- So the second layer takes $[o_1, o_2, o_3, o_4]$ as an input\n",
        "    - This layer has only one neuron, and it has 4 weights and 1 bias\n",
        "        - Because the input dimension is 4\n",
        "    - weights = $[u_1, u_2, u_3, u_4]$\n",
        "    - bias = $c$\n",
        "    - output = $u_1 o_1 + u_2 o_2 + u_3 o_3 + u_4 o_4 + c$\n",
        "        - = $u_1 (w_1 x + b_1) + u_2 (w_2 x + b_2) + u_3 (w_3 x + b_3) + u_4 (w_4 x + b_4) + c$\n",
        "        - = $ (u_1 w_1 + u_2 w_2 + u_3 w_3 + u_4 w_4) x + (u_1 b_1 + u_2 b_2 + u_3 b_3 + u_4 b_4 + c)$\n",
        "    - Therefore, if we replace the equation above using new symbol $v, d$,\n",
        "        - $v = u_1 w_1 + u_2 w_2 + u_3 w_3 + u_4 w_4$\n",
        "        - $d = u_1 b_1 + u_2 b_2 + u_3 b_3 + u_4 b_4 + c$\n",
        "        - output = $v x + d$\n",
        "            - Which is a linear equation\n",
        "- So, we can say that the combination of linear operations is also a linear operation\n",
        "    - **If** there is NO non-linear activation function between layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btRusUQpChvA"
      },
      "source": [
        "#### 2-8) Combination of Linear and Non-linear Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIoSFEteChvB"
      },
      "source": [
        "#### 2-9) Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFtIX2feChvB"
      },
      "source": [
        "#### 2-10) Visualizing the result\n",
        "- Draw how each neuron in the first layer is activated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4k1bqyiTa3L"
      },
      "source": [
        "### Update plot in for loop\n",
        "```\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(10):\n",
        "  plt.plot([i], [i], 'o')\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(plt.gcf())\n",
        "  plt.close()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ8sA5wyBqnJ"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
