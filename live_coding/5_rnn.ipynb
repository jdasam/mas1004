{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/mas1004/blob/2024/live_coding/5_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_kJ3ZHxbpA2",
        "outputId": "88abf091-2822-4fbd-bb6c-2c34a1979b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-26 06:01:42--  https://archive.ics.uci.edu/static/public/591/gender+by+name.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘gender+by+name.zip’\n",
            "\n",
            "gender+by+name.zip      [       <=>          ]   3.60M  1.87MB/s    in 1.9s    \n",
            "\n",
            "2024-11-26 06:01:45 (1.87 MB/s) - ‘gender+by+name.zip’ saved [3774735]\n",
            "\n",
            "Archive:  gender+by+name.zip\n",
            " extracting: name_gender_dataset.csv  \n"
          ]
        }
      ],
      "source": [
        "# download data\n",
        "!wget https://archive.ics.uci.edu/static/public/591/gender+by+name.zip\n",
        "!unzip gender+by+name.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-zH5vtQXbpA2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('name_gender_dataset.csv')\n",
        "unique_gender_df = df.drop_duplicates(['Name'])\n",
        "names = unique_gender_df['Name'].values\n",
        "genders = unique_gender_df['Gender'].values\n",
        "\n",
        "# names.tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `nn.Linear()`: $\\mathbf{Wx} + \\mathbf{b}$\n",
        "  - x $\\in \\mathbb{R}^d$\n",
        "\n",
        "- `RNN`\n",
        "  - $h_t = \\tanh (W_{xh}x_t + W_{hh}h_{t-1} + b) $\n",
        "  -  $h_t = \\tanh (W_{xh}x_t + b_x + W_{hh}h_{t-1} + b_h) $"
      ],
      "metadata": {
        "id": "362uCVRQcWa2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOmrvfRYefu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Recurrent Neural Network\n",
        "import torch\n",
        "previous_hidden_state = torch.randn(7).tanh()\n",
        "current_input = torch.randn(5)\n",
        "\n",
        "print(previous_hidden_state, current_input)"
      ],
      "metadata": {
        "id": "lAXYtM89cFA4",
        "outputId": "0c803479-85cd-4af1-9ab9-14cd552c11e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4477,  0.0689, -0.8287,  0.0499,  0.0322, -0.6541,  0.7924]) tensor([ 0.2123, -1.3285, -0.3113,  1.0953,  0.8298])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make longer input\n",
        "number_of_tokens = 9\n",
        "token_embedding_size = 5\n",
        "\n",
        "input_sequence = torch.randn((number_of_tokens, token_embedding_size))\n",
        "input_sequence.shape"
      ],
      "metadata": {
        "id": "qHT1FjXwhWiC",
        "outputId": "dd1ac089-1f38-4db5-bc22-dce324906733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cur_input in input_sequence:\n",
        "  print(cur_input)\n",
        "# for i in range(len(input_sequence)):\n",
        "#   print(input_sequence[i])"
      ],
      "metadata": {
        "id": "Kt17-6nUjMPP",
        "outputId": "e8d81501-fe0e-447d-da52-dc67bd1f3d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4327, -0.7840, -0.1075,  2.2716, -0.5705])\n",
            "tensor([-0.5104, -1.6307,  0.5388, -1.5380,  0.8719])\n",
            "tensor([-1.4114,  2.5902, -0.2259,  0.9653,  0.9899])\n",
            "tensor([-1.3992,  0.3997,  0.6053, -0.0415,  1.0008])\n",
            "tensor([-1.4440,  1.2071,  2.5974,  0.3771,  0.5250])\n",
            "tensor([ 0.3963, -0.3961, -0.2312,  0.7685, -1.4756])\n",
            "tensor([-0.2272,  0.8759, -1.0998, -0.1117,  1.8035])\n",
            "tensor([-0.8828, -0.5067,  0.2981, -1.9616,  0.6948])\n",
            "tensor([ 0.2233, -0.7568, -1.3587, -0.1077,  1.1827])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyRNN:\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    self.xh = nn.Linear(input_dim, output_dim)\n",
        "    self.hh = nn.Linear(output_dim, output_dim, bias=False)\n",
        "    self.hidden_size = output_dim\n",
        "\n",
        "  def run_one_step(self, current_input, previous_output):\n",
        "    out = self.xh(current_input) + self.hh(previous_output)\n",
        "    out = out.tanh()\n",
        "    return out\n",
        "\n",
        "  def run_sequence(self, input_sequence, last_hidden_state=None):\n",
        "    if last_hidden_state is None:\n",
        "      last_hidden_state = torch.zeros(self.hidden_size)\n",
        "\n",
        "    outputs = []\n",
        "    for cur_input in input_sequence:\n",
        "      last_hidden_state = self.run_one_step(cur_input, last_hidden_state)\n",
        "      outputs.append(last_hidden_state)\n",
        "\n",
        "    return torch.stack(outputs)\n",
        "\n",
        "\n",
        "rnn = MyRNN(input_dim=5, output_dim=7)\n",
        "# rnn.run_one_step(current_input, previous_hidden_state)\n",
        "rnn.run_sequence(input_sequence)"
      ],
      "metadata": {
        "id": "tlA_5rimegOm",
        "outputId": "824b3243-6d86-4819-dc76-3ec7542d2fdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9215, -0.2476,  0.5453,  0.2238,  0.2572,  0.5746, -0.6511],\n",
              "        [ 0.0955,  0.6433,  0.0959, -0.6613, -0.3291, -0.4824, -0.6279],\n",
              "        [ 0.8431, -0.6233,  0.7644,  0.6869,  0.4335, -0.2522, -0.8306],\n",
              "        [ 0.3031, -0.1443,  0.4274, -0.4197,  0.4786, -0.6942, -0.6298],\n",
              "        [-0.3371, -0.5188,  0.8358, -0.6725,  0.6307, -0.7543, -0.8908],\n",
              "        [-0.8792,  0.0010, -0.2784, -0.1813, -0.3594, -0.4797, -0.3185],\n",
              "        [ 0.9235, -0.1221,  0.2369,  0.6476, -0.6858,  0.4014, -0.6706],\n",
              "        [ 0.5850,  0.3469, -0.4340, -0.8133,  0.0179, -0.7388,  0.4533],\n",
              "        [ 0.6535, -0.1869, -0.3994,  0.0867, -0.7126,  0.7177, -0.5490]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modified_sequence = input_sequence.clone()\n",
        "modified_sequence[4,:] = 0\n",
        "modified_sequence"
      ],
      "metadata": {
        "id": "LYKp0bUmkgPP",
        "outputId": "c38048cf-9153-4074-9be9-fd1147c428d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4327, -0.7840, -0.1075,  2.2716, -0.5705],\n",
              "        [-0.5104, -1.6307,  0.5388, -1.5380,  0.8719],\n",
              "        [-1.4114,  2.5902, -0.2259,  0.9653,  0.9899],\n",
              "        [-1.3992,  0.3997,  0.6053, -0.0415,  1.0008],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.3963, -0.3961, -0.2312,  0.7685, -1.4756],\n",
              "        [-0.2272,  0.8759, -1.0998, -0.1117,  1.8035],\n",
              "        [-0.8828, -0.5067,  0.2981, -1.9616,  0.6948],\n",
              "        [ 0.2233, -0.7568, -1.3587, -0.1077,  1.1827]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.run_sequence(modified_sequence)"
      ],
      "metadata": {
        "id": "cVaMWnHBkqo5",
        "outputId": "375da038-d3aa-4a29-e7b9-d2497b529166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9215, -0.2476,  0.5453,  0.2238,  0.2572,  0.5746, -0.6511],\n",
              "        [ 0.0955,  0.6433,  0.0959, -0.6613, -0.3291, -0.4824, -0.6279],\n",
              "        [ 0.8431, -0.6233,  0.7644,  0.6869,  0.4335, -0.2522, -0.8306],\n",
              "        [ 0.3031, -0.1443,  0.4274, -0.4197,  0.4786, -0.6942, -0.6298],\n",
              "        [-0.2250, -0.1665, -0.2671, -0.3248, -0.2643, -0.3370, -0.4313],\n",
              "        [-0.8495,  0.0544, -0.2189, -0.3411, -0.4572, -0.2946,  0.1164],\n",
              "        [ 0.9310, -0.1134,  0.3799,  0.6804, -0.6877,  0.5034, -0.5731],\n",
              "        [ 0.5928,  0.3523, -0.3925, -0.7945,  0.0758, -0.7334,  0.5044],\n",
              "        [ 0.6600, -0.1895, -0.3985,  0.1009, -0.7144,  0.7144, -0.5422]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These are the examples of names\n",
        "names.tolist()[:20]"
      ],
      "metadata": {
        "id": "sTbDr5IlFDnb",
        "outputId": "d3479bce-ba3d-4fca-803d-d8155d549959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['James',\n",
              " 'John',\n",
              " 'Robert',\n",
              " 'Michael',\n",
              " 'William',\n",
              " 'Mary',\n",
              " 'David',\n",
              " 'Joseph',\n",
              " 'Richard',\n",
              " 'Charles',\n",
              " 'Thomas',\n",
              " 'Christopher',\n",
              " 'Daniel',\n",
              " 'Matthew',\n",
              " 'Elizabeth',\n",
              " 'Patricia',\n",
              " 'Jennifer',\n",
              " 'Anthony',\n",
              " 'George',\n",
              " 'Linda']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What we want to do: Make names as a list of token indices\n",
        "# We call that procedure 'tokenization'\n",
        "\n",
        "# First thing we have to do: get the vocabulary\n",
        "# vocab = ['a', 'b', 'c', 'd', ...]\n",
        "# Gather every possible character in the corpus\n",
        "\n",
        "name_list = names.tolist()\n",
        "print(type(name_list), type(name_list[0]))\n",
        "\n",
        "idx = 0\n",
        "name = name_list[idx]\n",
        "unique_char = set(name)\n",
        "\n",
        "entire_unique_char = set([char for name in name_list for char in name.lower()])\n",
        "len(entire_unique_char)"
      ],
      "metadata": {
        "id": "dBNA2MxtFe38",
        "outputId": "33833350-3435-462d-b011-e16a1d385354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'str'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name.lower()"
      ],
      "metadata": {
        "id": "Pp1b7qt0Intg",
        "outputId": "efd7f13d-2f00-46c9-8317-a85615b67d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'james'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[name for name in name_list if '@' in name ]"
      ],
      "metadata": {
        "id": "bLeTL2mAHZGD",
        "outputId": "cfccb550-3872-4a23-ce3c-baa28c2c35ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bhagwati@Shinnu',\n",
              " 'Soni@',\n",
              " 'Sonu@Akil',\n",
              " 'Vivek@',\n",
              " 'Anjali@Rinku',\n",
              " 'Anno@',\n",
              " 'Bharati@Ruchika',\n",
              " 'Ekta@Mamta',\n",
              " 'Guddiya@Guddi',\n",
              " 'Kajal@',\n",
              " 'Kajal@Sundri',\n",
              " 'Khushbari@',\n",
              " 'Kimmi@Neelam',\n",
              " 'Krishna@Manisha',\n",
              " 'Kritika@Kittu',\n",
              " 'Laxmi@Nankai',\n",
              " 'Mahi@Munasvi',\n",
              " 'Mamta@Lalita',\n",
              " 'Manju@',\n",
              " 'Megha@Sandhya',\n",
              " 'Muskan@Ruksher',\n",
              " 'Neeta@Narayani',\n",
              " 'Nikita@Niki',\n",
              " 'Nisha@Neelam',\n",
              " 'Pooja@Neha',\n",
              " 'Premwati@Radha',\n",
              " 'Puja@Rakhi',\n",
              " 'Rahi@',\n",
              " 'Rajeswary@Rajo@Chanchal',\n",
              " 'Rajkumari@Babli',\n",
              " 'Rashid@Robhi',\n",
              " 'Ratni@Jasoda',\n",
              " 'Sabana@Moni',\n",
              " 'Sabenoor@Tamanna',\n",
              " 'Sabnam@',\n",
              " 'Sabreen@',\n",
              " 'Sagita@Harsita',\n",
              " 'Sakina@Kajal',\n",
              " 'Sawana@Pinki',\n",
              " 'Shagufta@Munny',\n",
              " 'Shakshi@',\n",
              " 'Shakuntala@Pooja,',\n",
              " 'Shanawaz@Heena',\n",
              " 'Shefali@Puja',\n",
              " 'Shivani@Prachi',\n",
              " 'Sujata@',\n",
              " 'Yasmeen@Lali',\n",
              " 'Yoshoda@',\n",
              " 'Ankit@',\n",
              " 'Ankit@Udai',\n",
              " 'Ankur@',\n",
              " 'Annu@Anil',\n",
              " 'Ashwani@Manish',\n",
              " 'Batu@',\n",
              " 'Bharat@Dholu',\n",
              " 'Dhiraj@Dhirendar',\n",
              " 'Gaurav@',\n",
              " 'Golu@',\n",
              " 'Hemant@Teeku',\n",
              " 'Jitender@',\n",
              " 'Jitender@Jita',\n",
              " 'Jitu@Jitendra',\n",
              " 'Kalu@',\n",
              " 'Kamal@',\n",
              " 'Kaushal@Lala',\n",
              " 'Manoj@',\n",
              " 'Manoj@Monu',\n",
              " 'Monu@',\n",
              " 'Monu@Arun',\n",
              " 'Nabi@',\n",
              " 'Naitik@Kanaya',\n",
              " 'Nannu@Jaypal',\n",
              " 'Narender@Narender',\n",
              " 'Nishant@',\n",
              " 'Nitin@',\n",
              " 'Parvesh@Pankaj',\n",
              " 'Patik@Monu',\n",
              " 'Pradeep@Kale',\n",
              " 'Rahul@Akash',\n",
              " 'Rajbir@Changa',\n",
              " 'Rajeshwar@Moni',\n",
              " 'Raju@Rajesh',\n",
              " 'Ramu@',\n",
              " 'Ravi@',\n",
              " 'Sabbar@',\n",
              " 'Sandeep@Sonu',\n",
              " 'Sanjay@Ghasu',\n",
              " 'Sanjay@Sonu',\n",
              " 'Santlal@Golu',\n",
              " 'Sany@Aman',\n",
              " 'Satish@Moolchand@Baba',\n",
              " 'Shankar@',\n",
              " 'Sunil@',\n",
              " 'Sunil@Monu',\n",
              " 'Surender@Mannu',\n",
              " 'Suresh@Tinku',\n",
              " 'Titu@Devender',\n",
              " 'Toni@Punit',\n",
              " 'Vinod@Badri']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count the appearance of each character\n",
        "from collections import Counter\n",
        "char_counter = Counter([char for name in name_list for char in name.lower()])\n",
        "\n",
        "omitted_chars = []\n",
        "for key, value in char_counter.items():\n",
        "  # print(key, value)\n",
        "  if value < 200:\n",
        "    omitted_chars.append(key)\n",
        "omitted_chars = set(omitted_chars)"
      ],
      "metadata": {
        "id": "RPfUvRPHH3VD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_counter.items()"
      ],
      "metadata": {
        "id": "AFOnFBdJHA1K",
        "outputId": "c5e1762c-106f-494e-e2a9-df9705acf481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('j', 15237), ('a', 153757), ('m', 28613), ('e', 99229), ('s', 42583), ('o', 36099), ('h', 40331), ('n', 80335), ('r', 59497), ('b', 11706), ('t', 34400), ('i', 78409), ('c', 18366), ('l', 57474), ('w', 4891), ('y', 33901), ('d', 26959), ('v', 10454), ('p', 6159), ('z', 7979), ('f', 4638), ('g', 9531), ('u', 18951), ('k', 21253), ('x', 1806), ('q', 2468), ('-', 7257), ('à', 3), ('.', 111), ('…', 13), (\"'\", 254), ('0', 5), ('œ', 2), ('@', 101), (',', 9), ('/', 6), ('\"', 2), (';', 8), ('¡', 1), ('&', 1), ('(', 2), ('?', 3), ('1', 1), ('9', 2), ('5', 2), ('7', 2), ('ö', 1), (')', 1), ('[', 1), ('8', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'james1'\n",
        "\n",
        "(set(name) - omitted_chars) == set(name)"
      ],
      "metadata": {
        "id": "3InSOyCFKaRS",
        "outputId": "f2c932cc-df5b-42b4-9db1-1236ab1e14aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using our omitted_chars, we can filter out the name_list\n",
        "\n",
        "\n",
        "filtered_names = [name.lower() for name in name_list if (set(name) - omitted_chars) == set(name)]\n",
        "len(filtered_names), len(name_list)"
      ],
      "metadata": {
        "id": "qX9E1Fn7JdFL",
        "outputId": "87d52ccf-66ba-476e-cdfd-22d407abd4e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(133650, 133910)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocabulary(list_of_names):\n",
        "  entire_chars = [char for name in list_of_names for char in name]\n",
        "  vocab = set(entire_chars)\n",
        "  return sorted(list(vocab))\n",
        "\n",
        "vocab = get_vocabulary(filtered_names)\n",
        "vocab, len(vocab)"
      ],
      "metadata": {
        "id": "VTvIOOztLKIJ",
        "outputId": "de664886-314f-4a73-dedf-9db23bfa76d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([\"'\",\n",
              "  '-',\n",
              "  'a',\n",
              "  'b',\n",
              "  'c',\n",
              "  'd',\n",
              "  'e',\n",
              "  'f',\n",
              "  'g',\n",
              "  'h',\n",
              "  'i',\n",
              "  'j',\n",
              "  'k',\n",
              "  'l',\n",
              "  'm',\n",
              "  'n',\n",
              "  'o',\n",
              "  'p',\n",
              "  'q',\n",
              "  'r',\n",
              "  's',\n",
              "  't',\n",
              "  'u',\n",
              "  'v',\n",
              "  'w',\n",
              "  'x',\n",
              "  'y',\n",
              "  'z'],\n",
              " 28)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert name into list of vocabulary index\n",
        "# james -> [int int int int int]\n",
        "\n",
        "name = filtered_names[0]\n",
        "\n",
        "converted_indices = []\n",
        "for char in name:\n",
        "  # get the index of the character in the vocabulary\n",
        "  idx = vocab.index(char)\n",
        "  print(char, idx)\n",
        "  converted_indices.append(idx)\n",
        "\n",
        "def encode(vocab, input):\n",
        "  return [vocab.index(char) for char in input]\n",
        "\n",
        "converted_indices = encode(vocab, name)\n",
        "converted_indices"
      ],
      "metadata": {
        "id": "Nyo497y2Lq1K",
        "outputId": "24cd0af6-ed94-4fc2-ab0e-f49160b11ed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j 11\n",
            "a 2\n",
            "m 14\n",
            "e 6\n",
            "s 20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11, 2, 14, 6, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(vocab, input):\n",
        "  # input: list of integer\n",
        "  return ''.join([vocab[idx] for idx in input])\n",
        "\n",
        "decode(vocab, converted_indices)"
      ],
      "metadata": {
        "id": "82Z7wwWOM2FV",
        "outputId": "7cb98189-cdf1-49d3-b9c2-379e6c31fd17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'james'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted_names = [encode(vocab, name) for name in filtered_names]\n",
        "len(converted_names), converted_names[10]"
      ],
      "metadata": {
        "id": "ynsO8Y9vNmxn",
        "outputId": "2108441b-4e77-4db4-954d-85de62605606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(133650, [21, 9, 16, 14, 2, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert it into tensor, and make a single training example\n",
        "\n",
        "# name_in_int = converted_names[10]\n",
        "name = 'aarona'\n",
        "name_in_int = encode(vocab, name)\n",
        "# name_in_int = [3, 3, ]\n",
        "\n",
        "tensor_input = torch.LongTensor(name_in_int)\n",
        "tensor_input"
      ],
      "metadata": {
        "id": "i4pA2UoTN-6J",
        "outputId": "95f2222c-583c-4bde-97fe-a52305876c61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  2, 19, 16, 15,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make embedding vector for each character in the vocabulary\n",
        "# Let's set the embedding size = 17\n",
        "\n",
        "char_emb_layer = nn.Embedding(len(vocab), embedding_dim=17)\n",
        "\n",
        "embs = char_emb_layer(tensor_input)\n",
        "embs"
      ],
      "metadata": {
        "id": "3ruWMgcdOYy7",
        "outputId": "98c9dbbf-122d-4657-cddc-7548ccff1a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5584, -0.7063,  0.0653, -0.0191, -0.4693, -0.5989,  1.0094, -1.3406,\n",
              "          0.6128,  0.9527,  0.2929, -0.2907,  1.5477, -0.7131, -0.1934, -1.8459,\n",
              "         -0.7947],\n",
              "        [ 0.5584, -0.7063,  0.0653, -0.0191, -0.4693, -0.5989,  1.0094, -1.3406,\n",
              "          0.6128,  0.9527,  0.2929, -0.2907,  1.5477, -0.7131, -0.1934, -1.8459,\n",
              "         -0.7947],\n",
              "        [-0.0473, -0.7585,  1.2368,  0.2355,  1.3041, -1.7071,  0.6098,  1.2954,\n",
              "         -0.7085, -1.0002,  0.4791, -0.5579, -0.8564, -0.7666,  0.3820, -0.7672,\n",
              "          0.7581],\n",
              "        [ 1.9613,  1.7548,  0.4391,  0.4485, -0.1559,  1.7656,  1.9222, -0.4681,\n",
              "         -0.0102, -1.2229, -0.2372,  1.4594, -0.3267,  1.0597,  0.2514, -0.0564,\n",
              "          1.1611],\n",
              "        [ 0.4920,  0.7944,  0.3562,  0.6819, -1.7091, -0.7011,  0.1752,  0.8004,\n",
              "          0.5278, -1.2903, -1.1066,  1.0445, -1.7812, -1.6004, -0.5135,  0.7133,\n",
              "          0.7667],\n",
              "        [ 0.5584, -0.7063,  0.0653, -0.0191, -0.4693, -0.5989,  1.0094, -1.3406,\n",
              "          0.6128,  0.9527,  0.2929, -0.2907,  1.5477, -0.7131, -0.1934, -1.8459,\n",
              "         -0.7947]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next step: feed this sequence of embeddings to RNN\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "rnn = MyRNN(input_dim=17, output_dim=32)\n",
        "output_by_chars = rnn.run_sequence(embs)\n",
        "\n",
        "# We have calculated a complex context vector for each char\n",
        "output_by_chars[3] # a output of RNN after reading every chars until (including) 3rd character\n",
        "\n"
      ],
      "metadata": {
        "id": "h95uFxtWPjnI",
        "outputId": "a313a17e-d53b-4b3f-fd88-7e82611d9365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.6408, -0.4566,  0.4528, -0.5318, -0.0338, -0.0987,  0.7928,  0.0440,\n",
              "        -0.8226,  0.9018, -0.6092,  0.6840, -0.1854,  0.4610, -0.5393, -0.6151,\n",
              "        -0.8082, -0.3435, -0.0083, -0.6168, -0.1027, -0.0746, -0.2517,  0.1824,\n",
              "         0.8443, -0.5128, -0.0966, -0.3882, -0.8354, -0.6599, -0.4508, -0.7143],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_input[4]"
      ],
      "metadata": {
        "id": "4g4T-2gOSoFI",
        "outputId": "64939034-1489-46f4-cdab-d2f1dc73e15b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on these output, we have to predict the following char\n",
        "# How can we compute the following character, using output_by_chars?\n",
        "\n",
        "# How can we compute which would be the 4-th character using output_by_chars[3]\n",
        "# Do we have to make our model to predict one single character?\n",
        "# What would be other way to predict the next character?\n",
        "\n",
        "# We make neural network to predict probability distribution of next character\n",
        "# across the entire vocab\n",
        "\n",
        "projection_layer = nn.Linear(32, len(vocab))\n",
        "logits = projection_layer(output_by_chars)\n",
        "print(output_by_chars.shape, logits.shape)\n",
        "\n",
        "probs = torch.softmax(logits, dim=-1)\n",
        "probs, tensor_input\n"
      ],
      "metadata": {
        "id": "mlowaN8EQjFv",
        "outputId": "575f473c-e80d-4d5b-f3f9-20082785c5d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 32]) torch.Size([6, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0308, 0.0295, 0.0373, 0.0453, 0.0404, 0.0275, 0.0274, 0.0311, 0.0251,\n",
              "          0.0606, 0.0327, 0.0223, 0.0241, 0.0462, 0.0234, 0.0329, 0.0401, 0.0356,\n",
              "          0.0476, 0.0243, 0.0312, 0.0559, 0.0445, 0.0345, 0.0365, 0.0265, 0.0416,\n",
              "          0.0452],\n",
              "         [0.0308, 0.0268, 0.0357, 0.0447, 0.0439, 0.0298, 0.0239, 0.0267, 0.0245,\n",
              "          0.0541, 0.0349, 0.0181, 0.0220, 0.0452, 0.0254, 0.0326, 0.0361, 0.0339,\n",
              "          0.0562, 0.0254, 0.0283, 0.0541, 0.0536, 0.0391, 0.0428, 0.0200, 0.0454,\n",
              "          0.0459],\n",
              "         [0.0390, 0.0247, 0.0354, 0.0398, 0.0412, 0.0265, 0.0251, 0.0330, 0.0323,\n",
              "          0.0377, 0.0416, 0.0258, 0.0208, 0.0334, 0.0356, 0.0290, 0.0413, 0.0246,\n",
              "          0.0544, 0.0417, 0.0310, 0.0593, 0.0380, 0.0345, 0.0433, 0.0177, 0.0583,\n",
              "          0.0349],\n",
              "         [0.0373, 0.0391, 0.0466, 0.0340, 0.0429, 0.0320, 0.0228, 0.0274, 0.0364,\n",
              "          0.0573, 0.0459, 0.0289, 0.0209, 0.0400, 0.0426, 0.0306, 0.0377, 0.0452,\n",
              "          0.0448, 0.0406, 0.0415, 0.0268, 0.0464, 0.0319, 0.0260, 0.0214, 0.0219,\n",
              "          0.0310],\n",
              "         [0.0238, 0.0385, 0.0719, 0.0327, 0.0260, 0.0270, 0.0380, 0.0392, 0.0363,\n",
              "          0.0388, 0.0529, 0.0307, 0.0344, 0.0326, 0.0306, 0.0530, 0.0364, 0.0309,\n",
              "          0.0438, 0.0199, 0.0161, 0.0457, 0.0276, 0.0273, 0.0244, 0.0336, 0.0476,\n",
              "          0.0400],\n",
              "         [0.0269, 0.0325, 0.0406, 0.0404, 0.0360, 0.0273, 0.0355, 0.0314, 0.0270,\n",
              "          0.0549, 0.0354, 0.0196, 0.0262, 0.0445, 0.0214, 0.0377, 0.0376, 0.0342,\n",
              "          0.0402, 0.0234, 0.0271, 0.0682, 0.0508, 0.0335, 0.0325, 0.0258, 0.0450,\n",
              "          0.0446]], grad_fn=<SoftmaxBackward0>),\n",
              " tensor([ 2,  2, 19, 16, 15,  2]))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(probs)):\n",
        "  prob_dist_of_i = probs[i]\n",
        "  next_char = tensor_input[i+1]\n",
        "  prob_of_correct_next_char = prob_dist_of_i[next_char]\n",
        "  print(prob_of_correct_next_char)\n",
        "\n",
        "# This makes error because we don't have next character to the last character\n",
        "\n",
        "# we append <end> token to the end of the sequence.\n"
      ],
      "metadata": {
        "id": "OLcXqTpgUV6A",
        "outputId": "c5915bfa-a612-4e25-bbdf-11fa0bc9b534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0373, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0254, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0413, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0306, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0719, grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 6 is out of bounds for dimension 0 with size 6",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-f9a77430e6dc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprob_dist_of_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprob_of_correct_next_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob_dist_of_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_of_correct_next_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for dimension 0 with size 6"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}