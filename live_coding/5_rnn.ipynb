{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/mas1004/blob/2024/live_coding/5_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_kJ3ZHxbpA2",
        "outputId": "71985d0c-7568-4bac-f54f-18b32741165a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-03 06:05:56--  https://archive.ics.uci.edu/static/public/591/gender+by+name.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘gender+by+name.zip’\n",
            "\n",
            "\rgender+by+name.zip      [<=>                 ]       0  --.-KB/s               \rgender+by+name.zip      [ <=>                ]   3.60M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-12-03 06:05:56 (46.2 MB/s) - ‘gender+by+name.zip’ saved [3774735]\n",
            "\n",
            "Archive:  gender+by+name.zip\n",
            " extracting: name_gender_dataset.csv  \n"
          ]
        }
      ],
      "source": [
        "# download data\n",
        "!wget https://archive.ics.uci.edu/static/public/591/gender+by+name.zip\n",
        "!unzip gender+by+name.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-zH5vtQXbpA2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('name_gender_dataset.csv')\n",
        "unique_gender_df = df.drop_duplicates(['Name'])\n",
        "names = unique_gender_df['Name'].values\n",
        "genders = unique_gender_df['Gender'].values\n",
        "\n",
        "# names.tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `nn.Linear()`: $\\mathbf{Wx} + \\mathbf{b}$\n",
        "  - x $\\in \\mathbb{R}^d$\n",
        "\n",
        "- `RNN`\n",
        "  - $h_t = \\tanh (W_{xh}x_t + W_{hh}h_{t-1} + b) $\n",
        "  -  $h_t = \\tanh (W_{xh}x_t + b_x + W_{hh}h_{t-1} + b_h) $"
      ],
      "metadata": {
        "id": "362uCVRQcWa2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOmrvfRYefu0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Recurrent Neural Network\n",
        "import torch\n",
        "previous_hidden_state = torch.randn(7).tanh()\n",
        "current_input = torch.randn(5)\n",
        "\n",
        "print(previous_hidden_state, current_input)"
      ],
      "metadata": {
        "id": "lAXYtM89cFA4",
        "outputId": "45bc62da-8bfb-435b-d60a-3196db994e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3173,  0.9449,  0.6065, -0.6072,  0.1983,  0.8677, -0.6661]) tensor([-0.3024, -0.3168,  0.6409,  0.9277, -1.4482])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make longer input\n",
        "number_of_tokens = 9\n",
        "token_embedding_size = 5\n",
        "\n",
        "input_sequence = torch.randn((number_of_tokens, token_embedding_size))\n",
        "input_sequence.shape"
      ],
      "metadata": {
        "id": "qHT1FjXwhWiC",
        "outputId": "f46e8043-9203-4f47-ca02-c055f6b0088d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cur_input in input_sequence:\n",
        "  print(cur_input)\n",
        "# for i in range(len(input_sequence)):\n",
        "#   print(input_sequence[i])"
      ],
      "metadata": {
        "id": "Kt17-6nUjMPP",
        "outputId": "fc7c5df7-380c-4da3-b38e-33eb2523f86c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4678,  1.4039,  1.2724,  0.7242,  0.1369])\n",
            "tensor([ 1.8653, -0.2876, -0.4275,  0.2890,  0.3136])\n",
            "tensor([ 1.7496,  0.3859, -0.4404,  2.4725, -1.4289])\n",
            "tensor([-0.3190, -0.5844, -0.2130, -0.7306,  0.1002])\n",
            "tensor([ 0.0845,  1.6278, -1.0607, -0.7950, -1.4101])\n",
            "tensor([-0.6788,  1.0926, -0.7951, -0.4779, -0.1811])\n",
            "tensor([ 0.2109, -0.6911,  3.0780,  0.1557,  0.1850])\n",
            "tensor([ 0.0059, -0.3190, -2.0030,  0.2687, -1.2978])\n",
            "tensor([ 0.1745, -1.4658,  0.2853, -1.4561, -0.6562])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyRNN(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__() # init nn.Module\n",
        "    self.xh = nn.Linear(input_dim, output_dim)\n",
        "    self.hh = nn.Linear(output_dim, output_dim, bias=False)\n",
        "    self.hidden_size = output_dim\n",
        "\n",
        "  def run_one_step(self, current_input, previous_output):\n",
        "    out = self.xh(current_input) + self.hh(previous_output)\n",
        "    out = out.tanh()\n",
        "    return out\n",
        "\n",
        "  def run_sequence(self, input_sequence, last_hidden_state=None):\n",
        "    if last_hidden_state is None:\n",
        "      last_hidden_state = torch.zeros(self.hidden_size)\n",
        "\n",
        "    outputs = []\n",
        "    for cur_input in input_sequence:\n",
        "      last_hidden_state = self.run_one_step(cur_input, last_hidden_state)\n",
        "      outputs.append(last_hidden_state)\n",
        "\n",
        "    return torch.stack(outputs)\n",
        "\n",
        "\n",
        "rnn = MyRNN(input_dim=5, output_dim=7)\n",
        "# rnn.run_one_step(current_input, previous_hidden_state)\n",
        "rnn.run_sequence(input_sequence)"
      ],
      "metadata": {
        "id": "tlA_5rimegOm",
        "outputId": "0580c40a-9c5f-40a2-be22-451d6007d3c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[     0.8006,     -0.5977,     -0.5627,      0.5353,     -0.5174,\n",
              "             -0.8820,      0.3132],\n",
              "        [    -0.5037,      0.7343,      0.8435,      0.3191,      0.0282,\n",
              "              0.1454,     -0.1692],\n",
              "        [     0.7459,     -0.1039,     -0.0273,      0.3499,      0.6929,\n",
              "              0.0781,     -0.5515],\n",
              "        [     0.3387,     -0.4092,     -0.1687,     -0.1845,     -0.2116,\n",
              "              0.2101,      0.1751],\n",
              "        [     0.3223,     -0.3914,     -0.7014,      0.6341,      0.2526,\n",
              "              0.4638,      0.1503],\n",
              "        [     0.4014,     -0.5127,     -0.6060,      0.2649,     -0.0704,\n",
              "             -0.1180,     -0.0504],\n",
              "        [     0.7136,      0.0855,      0.3885,     -0.0006,     -0.8240,\n",
              "             -0.6849,      0.8029],\n",
              "        [    -0.1088,     -0.1182,      0.1990,     -0.1582,      0.5275,\n",
              "              0.7881,      0.0888],\n",
              "        [     0.1171,     -0.1719,      0.2706,     -0.6426,     -0.4357,\n",
              "              0.9117,      0.4036]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9JLOIG8R5cm",
        "outputId": "b8d5304b-4246-4874-8c53-698630438692"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7e56075f6e30>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modified_sequence = input_sequence.clone()\n",
        "modified_sequence[4,:] = 0\n",
        "modified_sequence"
      ],
      "metadata": {
        "id": "LYKp0bUmkgPP",
        "outputId": "90fa230a-fbce-4ff1-d90e-b052165139b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4678,  1.4039,  1.2724,  0.7242,  0.1369],\n",
              "        [ 1.8653, -0.2876, -0.4275,  0.2890,  0.3136],\n",
              "        [ 1.7496,  0.3859, -0.4404,  2.4725, -1.4289],\n",
              "        [-0.3190, -0.5844, -0.2130, -0.7306,  0.1002],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.6788,  1.0926, -0.7951, -0.4779, -0.1811],\n",
              "        [ 0.2109, -0.6911,  3.0780,  0.1557,  0.1850],\n",
              "        [ 0.0059, -0.3190, -2.0030,  0.2687, -1.2978],\n",
              "        [ 0.1745, -1.4658,  0.2853, -1.4561, -0.6562]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.run_sequence(modified_sequence)"
      ],
      "metadata": {
        "id": "cVaMWnHBkqo5",
        "outputId": "bdbd0e4a-d9eb-4a85-aebf-ae0ec8f2ef1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4491,  0.7436, -0.3326, -0.6986, -0.1493,  0.5841, -0.3977],\n",
              "        [ 0.1771, -0.1574, -0.8689,  0.6430, -0.7092,  0.2139, -0.4559],\n",
              "        [-0.3918, -0.2071, -0.8474, -0.6216, -0.3701,  0.5428, -0.4207],\n",
              "        [ 0.5907,  0.6132, -0.1270,  0.4169, -0.5815,  0.0113, -0.3174],\n",
              "        [ 0.5231,  0.2292, -0.3312, -0.1325, -0.3965,  0.0677, -0.6019],\n",
              "        [ 0.7658,  0.4290,  0.5554, -0.3593, -0.6443,  0.3139, -0.2408],\n",
              "        [ 0.4173,  0.7681, -0.9562, -0.5064,  0.5598,  0.5991, -0.9360],\n",
              "        [ 0.3634, -0.5075,  0.1834,  0.4491, -0.2890,  0.0689, -0.7744],\n",
              "        [ 0.3907,  0.5382, -0.2845,  0.0790, -0.0104,  0.7353, -0.3339]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These are the examples of names\n",
        "names.tolist()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTbDr5IlFDnb",
        "outputId": "ba6683d9-c375-43e3-f492-b52514a7efd2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['James',\n",
              " 'John',\n",
              " 'Robert',\n",
              " 'Michael',\n",
              " 'William',\n",
              " 'Mary',\n",
              " 'David',\n",
              " 'Joseph',\n",
              " 'Richard',\n",
              " 'Charles',\n",
              " 'Thomas',\n",
              " 'Christopher',\n",
              " 'Daniel',\n",
              " 'Matthew',\n",
              " 'Elizabeth',\n",
              " 'Patricia',\n",
              " 'Jennifer',\n",
              " 'Anthony',\n",
              " 'George',\n",
              " 'Linda']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What we want to do: Make names as a list of token indices\n",
        "# We call that procedure 'tokenization'\n",
        "\n",
        "# First thing we have to do: get the vocabulary\n",
        "# vocab = ['a', 'b', 'c', 'd', ...]\n",
        "# Gather every possible character in the corpus\n",
        "\n",
        "name_list = names.tolist()\n",
        "print(type(name_list), type(name_list[0]))\n",
        "\n",
        "idx = 0\n",
        "name = name_list[idx]\n",
        "unique_char = set(name)\n",
        "\n",
        "entire_unique_char = set([char for name in name_list for char in name.lower()])\n",
        "len(entire_unique_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBNA2MxtFe38",
        "outputId": "0fd2c699-f962-4972-aec0-9e4727ece995"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'str'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Pp1b7qt0Intg",
        "outputId": "533094a7-3005-4ead-8c64-124501227f34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'james'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[name for name in name_list if '@' in name ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLeTL2mAHZGD",
        "outputId": "768bd458-4c71-4693-db3f-569449d5dcd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bhagwati@Shinnu',\n",
              " 'Soni@',\n",
              " 'Sonu@Akil',\n",
              " 'Vivek@',\n",
              " 'Anjali@Rinku',\n",
              " 'Anno@',\n",
              " 'Bharati@Ruchika',\n",
              " 'Ekta@Mamta',\n",
              " 'Guddiya@Guddi',\n",
              " 'Kajal@',\n",
              " 'Kajal@Sundri',\n",
              " 'Khushbari@',\n",
              " 'Kimmi@Neelam',\n",
              " 'Krishna@Manisha',\n",
              " 'Kritika@Kittu',\n",
              " 'Laxmi@Nankai',\n",
              " 'Mahi@Munasvi',\n",
              " 'Mamta@Lalita',\n",
              " 'Manju@',\n",
              " 'Megha@Sandhya',\n",
              " 'Muskan@Ruksher',\n",
              " 'Neeta@Narayani',\n",
              " 'Nikita@Niki',\n",
              " 'Nisha@Neelam',\n",
              " 'Pooja@Neha',\n",
              " 'Premwati@Radha',\n",
              " 'Puja@Rakhi',\n",
              " 'Rahi@',\n",
              " 'Rajeswary@Rajo@Chanchal',\n",
              " 'Rajkumari@Babli',\n",
              " 'Rashid@Robhi',\n",
              " 'Ratni@Jasoda',\n",
              " 'Sabana@Moni',\n",
              " 'Sabenoor@Tamanna',\n",
              " 'Sabnam@',\n",
              " 'Sabreen@',\n",
              " 'Sagita@Harsita',\n",
              " 'Sakina@Kajal',\n",
              " 'Sawana@Pinki',\n",
              " 'Shagufta@Munny',\n",
              " 'Shakshi@',\n",
              " 'Shakuntala@Pooja,',\n",
              " 'Shanawaz@Heena',\n",
              " 'Shefali@Puja',\n",
              " 'Shivani@Prachi',\n",
              " 'Sujata@',\n",
              " 'Yasmeen@Lali',\n",
              " 'Yoshoda@',\n",
              " 'Ankit@',\n",
              " 'Ankit@Udai',\n",
              " 'Ankur@',\n",
              " 'Annu@Anil',\n",
              " 'Ashwani@Manish',\n",
              " 'Batu@',\n",
              " 'Bharat@Dholu',\n",
              " 'Dhiraj@Dhirendar',\n",
              " 'Gaurav@',\n",
              " 'Golu@',\n",
              " 'Hemant@Teeku',\n",
              " 'Jitender@',\n",
              " 'Jitender@Jita',\n",
              " 'Jitu@Jitendra',\n",
              " 'Kalu@',\n",
              " 'Kamal@',\n",
              " 'Kaushal@Lala',\n",
              " 'Manoj@',\n",
              " 'Manoj@Monu',\n",
              " 'Monu@',\n",
              " 'Monu@Arun',\n",
              " 'Nabi@',\n",
              " 'Naitik@Kanaya',\n",
              " 'Nannu@Jaypal',\n",
              " 'Narender@Narender',\n",
              " 'Nishant@',\n",
              " 'Nitin@',\n",
              " 'Parvesh@Pankaj',\n",
              " 'Patik@Monu',\n",
              " 'Pradeep@Kale',\n",
              " 'Rahul@Akash',\n",
              " 'Rajbir@Changa',\n",
              " 'Rajeshwar@Moni',\n",
              " 'Raju@Rajesh',\n",
              " 'Ramu@',\n",
              " 'Ravi@',\n",
              " 'Sabbar@',\n",
              " 'Sandeep@Sonu',\n",
              " 'Sanjay@Ghasu',\n",
              " 'Sanjay@Sonu',\n",
              " 'Santlal@Golu',\n",
              " 'Sany@Aman',\n",
              " 'Satish@Moolchand@Baba',\n",
              " 'Shankar@',\n",
              " 'Sunil@',\n",
              " 'Sunil@Monu',\n",
              " 'Surender@Mannu',\n",
              " 'Suresh@Tinku',\n",
              " 'Titu@Devender',\n",
              " 'Toni@Punit',\n",
              " 'Vinod@Badri']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count the appearance of each character\n",
        "from collections import Counter\n",
        "char_counter = Counter([char for name in name_list for char in name.lower()])\n",
        "\n",
        "omitted_chars = []\n",
        "for key, value in char_counter.items():\n",
        "  # print(key, value)\n",
        "  if value < 200:\n",
        "    omitted_chars.append(key)\n",
        "omitted_chars = set(omitted_chars)"
      ],
      "metadata": {
        "id": "RPfUvRPHH3VD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_counter.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFOnFBdJHA1K",
        "outputId": "db74e904-d162-449f-c991-f2f21d556a4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('j', 15237), ('a', 153757), ('m', 28613), ('e', 99229), ('s', 42583), ('o', 36099), ('h', 40331), ('n', 80335), ('r', 59497), ('b', 11706), ('t', 34400), ('i', 78409), ('c', 18366), ('l', 57474), ('w', 4891), ('y', 33901), ('d', 26959), ('v', 10454), ('p', 6159), ('z', 7979), ('f', 4638), ('g', 9531), ('u', 18951), ('k', 21253), ('x', 1806), ('q', 2468), ('-', 7257), ('à', 3), ('.', 111), ('…', 13), (\"'\", 254), ('0', 5), ('œ', 2), ('@', 101), (',', 9), ('/', 6), ('\"', 2), (';', 8), ('¡', 1), ('&', 1), ('(', 2), ('?', 3), ('1', 1), ('9', 2), ('5', 2), ('7', 2), ('ö', 1), (')', 1), ('[', 1), ('8', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'james1'\n",
        "\n",
        "(set(name) - omitted_chars) == set(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3InSOyCFKaRS",
        "outputId": "68140b64-25ea-4895-d6c5-7339ccd8ab84"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using our omitted_chars, we can filter out the name_list\n",
        "\n",
        "\n",
        "filtered_names = [name.lower() for name in name_list if (set(name) - omitted_chars) == set(name)]\n",
        "len(filtered_names), len(name_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX9E1Fn7JdFL",
        "outputId": "91d2de8f-7537-4b1d-f9b4-59577c138a7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(133650, 133910)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocabulary(list_of_names):\n",
        "  entire_chars = [char for name in list_of_names for char in name]\n",
        "  vocab = set(entire_chars)\n",
        "  return sorted(list(vocab))\n",
        "\n",
        "vocab = get_vocabulary(filtered_names)\n",
        "vocab = ['@'] + vocab\n",
        "vocab, len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTvIOOztLKIJ",
        "outputId": "b25d2caa-b3f9-4011-f59e-c253ef77bdf2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['@',\n",
              "  \"'\",\n",
              "  '-',\n",
              "  'a',\n",
              "  'b',\n",
              "  'c',\n",
              "  'd',\n",
              "  'e',\n",
              "  'f',\n",
              "  'g',\n",
              "  'h',\n",
              "  'i',\n",
              "  'j',\n",
              "  'k',\n",
              "  'l',\n",
              "  'm',\n",
              "  'n',\n",
              "  'o',\n",
              "  'p',\n",
              "  'q',\n",
              "  'r',\n",
              "  's',\n",
              "  't',\n",
              "  'u',\n",
              "  'v',\n",
              "  'w',\n",
              "  'x',\n",
              "  'y',\n",
              "  'z'],\n",
              " 29)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert name into list of vocabulary index\n",
        "# james -> [int int int int int]\n",
        "\n",
        "name = filtered_names[0]\n",
        "\n",
        "converted_indices = []\n",
        "for char in name:\n",
        "  # get the index of the character in the vocabulary\n",
        "  idx = vocab.index(char)\n",
        "  print(char, idx)\n",
        "  converted_indices.append(idx)\n",
        "\n",
        "def encode(vocab, input):\n",
        "  input = '@' + input + '@' # @ to denote start/end\n",
        "  return [vocab.index(char) for char in input]\n",
        "\n",
        "converted_indices = encode(vocab, name)\n",
        "converted_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyo497y2Lq1K",
        "outputId": "a34e0d7d-0f6d-4bf1-a6f1-10290e9e815a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j 12\n",
            "a 3\n",
            "m 15\n",
            "e 7\n",
            "s 21\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 12, 3, 15, 7, 21, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(vocab, input):\n",
        "  # input: list of integer\n",
        "  return ''.join([vocab[idx] for idx in input if vocab[idx] != '@'])\n",
        "\n",
        "decode(vocab, converted_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "82Z7wwWOM2FV",
        "outputId": "b31b8572-6c9a-4963-816b-5a037e5e6dd5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'james'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted_names = [encode(vocab, name) for name in filtered_names]\n",
        "len(converted_names), converted_names[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynsO8Y9vNmxn",
        "outputId": "e1ca66d8-a791-4140-f242-a695c198ad79"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(133650, [21, 9, 16, 14, 2, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert it into tensor, and make a single training example\n",
        "\n",
        "# name_in_int = converted_names[10]\n",
        "name = 'aaron'\n",
        "name_in_int = encode(vocab, name)\n",
        "# name_in_int = [3, 3, ]\n",
        "\n",
        "tensor_input = torch.LongTensor(name_in_int)\n",
        "\n",
        "tensor_target = tensor_input[1:]\n",
        "tensor_input = tensor_input[:-1]\n",
        "\n",
        "print(tensor_input)\n",
        "print(tensor_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4pA2UoTN-6J",
        "outputId": "4fc3cf49-ba49-4786-be57-48fbf4155bbe"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  3,  3, 20, 17, 16])\n",
            "tensor([ 3,  3, 20, 17, 16,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make embedding vector for each character in the vocabulary\n",
        "# Let's set the embedding size = 17\n",
        "\n",
        "char_emb_layer = nn.Embedding(len(vocab), embedding_dim=17)\n",
        "\n",
        "embs = char_emb_layer(tensor_input)\n",
        "embs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ruWMgcdOYy7",
        "outputId": "7d4ea412-546f-4dde-8845-ad6f0b0aa3e6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5796,  0.7081,  1.4207,  0.5417, -0.0683,  0.5696, -0.4655,  0.6087,\n",
              "          0.1541,  0.0539, -1.2796,  0.9980,  0.0866,  2.8421, -1.9275,  1.4927,\n",
              "          1.6606],\n",
              "        [ 0.8316,  1.6500, -0.7968, -0.5850, -1.1649,  0.7503,  0.8240,  0.0804,\n",
              "         -0.0723, -1.2435,  0.2839,  1.0673,  1.3564,  0.2643,  0.5474, -0.0726,\n",
              "          0.3957],\n",
              "        [ 0.8316,  1.6500, -0.7968, -0.5850, -1.1649,  0.7503,  0.8240,  0.0804,\n",
              "         -0.0723, -1.2435,  0.2839,  1.0673,  1.3564,  0.2643,  0.5474, -0.0726,\n",
              "          0.3957],\n",
              "        [ 0.8655, -0.4688,  0.6007,  1.8388,  0.4143,  0.0430,  0.9003,  0.1143,\n",
              "          1.5205,  0.5342, -0.3439,  0.2680,  0.6183, -1.1763,  1.8757, -0.5936,\n",
              "         -0.4082],\n",
              "        [ 0.6767,  0.5776,  0.8381,  0.6378,  1.4960, -0.6097,  0.9543, -0.3541,\n",
              "          1.1127, -0.4236, -0.7799,  1.4248, -0.6570,  0.4750,  1.1819, -0.1733,\n",
              "          0.1519],\n",
              "        [-1.0359,  1.4109,  0.9710,  2.1984, -2.2950, -0.7237, -1.1068, -1.8270,\n",
              "         -1.5966,  1.8639, -0.1851,  0.8620, -1.5850,  0.1021, -0.1712, -0.8852,\n",
              "          0.5686]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next step: feed this sequence of embeddings to RNN\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "rnn = MyRNN(input_dim=17, output_dim=32)\n",
        "output_by_chars = rnn.run_sequence(embs)\n",
        "\n",
        "# We have calculated a complex context vector for each char\n",
        "output_by_chars[3] # a output of RNN after reading every chars until (including) 3rd character\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h95uFxtWPjnI",
        "outputId": "5fbe86c5-5589-4119-d350-71227cff52b8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0303,  0.0377, -0.2220, -0.0041,  0.8256,  0.2656,  0.6708,  0.5075,\n",
              "        -0.1148,  0.5205,  0.0997, -0.6013,  0.8623, -0.4349, -0.4576,  0.0483,\n",
              "         0.6074, -0.3170, -0.4717, -0.4734,  0.4475, -0.2512, -0.6310, -0.0113,\n",
              "         0.4841, -0.2324,  0.6963, -0.2245, -0.0095,  0.7370,  0.5999, -0.0390],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_input[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g4T-2gOSoFI",
        "outputId": "c117c426-331e-45be-8ac8-bb193b64434f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on these output, we have to predict the following char\n",
        "# How can we compute the following character, using output_by_chars?\n",
        "\n",
        "# How can we compute which would be the 4-th character using output_by_chars[3]\n",
        "# Do we have to make our model to predict one single character?\n",
        "# What would be other way to predict the next character?\n",
        "\n",
        "# We make neural network to predict probability distribution of next character\n",
        "# across the entire vocab\n",
        "\n",
        "projection_layer = nn.Linear(32, len(vocab))\n",
        "logits = projection_layer(output_by_chars)\n",
        "print(output_by_chars.shape, logits.shape)\n",
        "\n",
        "probs = torch.softmax(logits, dim=-1)\n",
        "probs, tensor_input\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlowaN8EQjFv",
        "outputId": "0b807776-5a6e-4672-ac9c-c7e6ac5dd7c9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 32]) torch.Size([6, 29])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0472, 0.0273, 0.0561, 0.0500, 0.0334, 0.0313, 0.0515, 0.0259, 0.0431,\n",
              "          0.0221, 0.0325, 0.0278, 0.0353, 0.0274, 0.0373, 0.0225, 0.0332, 0.0334,\n",
              "          0.0445, 0.0227, 0.0166, 0.0481, 0.0256, 0.0211, 0.0544, 0.0378, 0.0410,\n",
              "          0.0216, 0.0294],\n",
              "         [0.0368, 0.0500, 0.0259, 0.0329, 0.0353, 0.0236, 0.0216, 0.0351, 0.0368,\n",
              "          0.0230, 0.0473, 0.0299, 0.0300, 0.0231, 0.0301, 0.0430, 0.0334, 0.0547,\n",
              "          0.0351, 0.0176, 0.0377, 0.0380, 0.0410, 0.0212, 0.0292, 0.0349, 0.0314,\n",
              "          0.0412, 0.0601],\n",
              "         [0.0333, 0.0351, 0.0294, 0.0328, 0.0342, 0.0302, 0.0260, 0.0367, 0.0358,\n",
              "          0.0304, 0.0277, 0.0345, 0.0312, 0.0216, 0.0338, 0.0446, 0.0366, 0.0457,\n",
              "          0.0467, 0.0244, 0.0366, 0.0399, 0.0474, 0.0246, 0.0278, 0.0287, 0.0279,\n",
              "          0.0304, 0.0659],\n",
              "         [0.0375, 0.0355, 0.0332, 0.0350, 0.0314, 0.0308, 0.0290, 0.0371, 0.0225,\n",
              "          0.0351, 0.0439, 0.0352, 0.0408, 0.0338, 0.0224, 0.0411, 0.0225, 0.0205,\n",
              "          0.0366, 0.0374, 0.0334, 0.0527, 0.0455, 0.0425, 0.0246, 0.0221, 0.0397,\n",
              "          0.0399, 0.0384],\n",
              "         [0.0293, 0.0384, 0.0431, 0.0408, 0.0383, 0.0439, 0.0363, 0.0353, 0.0284,\n",
              "          0.0314, 0.0429, 0.0233, 0.0414, 0.0207, 0.0389, 0.0351, 0.0220, 0.0173,\n",
              "          0.0597, 0.0312, 0.0235, 0.0488, 0.0341, 0.0231, 0.0418, 0.0279, 0.0316,\n",
              "          0.0375, 0.0338],\n",
              "         [0.0264, 0.0460, 0.0523, 0.0492, 0.0442, 0.0283, 0.0274, 0.0258, 0.0339,\n",
              "          0.0229, 0.0467, 0.0220, 0.0469, 0.0328, 0.0232, 0.0247, 0.0338, 0.0350,\n",
              "          0.0268, 0.0257, 0.0214, 0.0422, 0.0295, 0.0228, 0.0533, 0.0266, 0.0482,\n",
              "          0.0505, 0.0318]], grad_fn=<SoftmaxBackward0>),\n",
              " tensor([ 0,  3,  3, 20, 17, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(probs)):\n",
        "  prob_dist_of_i = probs[i]\n",
        "  # next_char = tensor_input[i+1]\n",
        "  next_char = tensor_target[i]\n",
        "  prob_of_correct_next_char = prob_dist_of_i[next_char]\n",
        "  print(prob_of_correct_next_char)\n",
        "\n",
        "# This makes error because we don't have next character to the last character\n",
        "\n",
        "# we append <end> token to the end of the sequence.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLcXqTpgUV6A",
        "outputId": "2cbd7bf8-48be-42db-8e57-105f3cc28031"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0500, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0329, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0366, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0205, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0220, grad_fn=<SelectBackward0>)\n",
            "tensor(0.0264, grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate loss without for loop\n",
        "# we want to apply negative log-likelihood (NLL) loss\n",
        "# print(probs.shape)\n",
        "\n",
        "def get_nll_loss(probs, targets):\n",
        "  return -torch.log(probs[torch.arange(len(probs)), targets] + 1e-8).mean()\n",
        "\n",
        "loss = get_nll_loss(probs, tensor_target)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qd3FHZGNdax",
        "outputId": "03ddfc3d-c577-43e2-9c2e-0af7341f14e8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.5098, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Now we will wrap up everything into a dataset and model\n",
        "\n",
        "class Dataset:\n",
        "  def __init__(self, csv_fn='name_gender_dataset.csv'):\n",
        "    df = pd.read_csv(csv_fn)\n",
        "    unique_gender_df = df.drop_duplicates(['Name'])\n",
        "    names = unique_gender_df['Name'].values\n",
        "\n",
        "    self.name_list = names.tolist()\n",
        "    omitted_chars = self.get_omit_chars(self.name_list)\n",
        "    # filter the names\n",
        "    self.name_list = [name.lower() for name in name_list if (set(name) - omitted_chars) == set(name)]\n",
        "    random.shuffle(self.name_list)\n",
        "    self.tokenizer = Tokenizer(self.name_list)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.name_list)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # get the idx-th name\n",
        "    name = self.name_list[idx]\n",
        "    name_in_idxs = torch.LongTensor(self.tokenizer.encode(name))\n",
        "\n",
        "    input_seq = name_in_idxs[:-1] # slice before <end> token\n",
        "    target_seq = name_in_idxs[1:] # slice after <start> token\n",
        "    return input_seq, target_seq\n",
        "\n",
        "\n",
        "  def get_omit_chars(self, name_list, threshold=200):\n",
        "    char_counter = Counter([char for name in name_list for char in name.lower()])\n",
        "    omitted_chars = []\n",
        "    for key, value in char_counter.items():\n",
        "      if value < threshold:\n",
        "        omitted_chars.append(key)\n",
        "    omitted_chars = set(omitted_chars)\n",
        "    return omitted_chars\n",
        "\n",
        "class Tokenizer:\n",
        "  def __init__(self, list_of_names):\n",
        "    entire_chars = [char for name in list_of_names for char in name]\n",
        "    vocab = set(entire_chars)\n",
        "    vocab = sorted(list(vocab))\n",
        "    self.vocab = ['@'] + vocab\n",
        "\n",
        "  def encode(self, input):\n",
        "    input = '@' + input + '@' # @ to denote start/end\n",
        "    return [self.vocab.index(char) for char in input]\n",
        "\n",
        "  def decode(self, input):\n",
        "    # input: list of integer\n",
        "    return ''.join([self.vocab[idx] for idx in input if self.vocab[idx] != '@'])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.vocab)\n",
        "\n",
        "dataset = Dataset()\n",
        "input, target = dataset[0]\n",
        "print(f\"input: {input}\")\n",
        "print(f\"target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhiy1M55OWj7",
        "outputId": "5a08b4fa-8577-46b1-e8e4-640ca6f61360"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: tensor([ 0, 14, 11, 21,  3,  2, 21, 17, 18, 10, 11,  7])\n",
            "target: tensor([14, 11, 21,  3,  2, 21, 17, 18, 10, 11,  7,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.tokenizer.encode('aaron')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPWC15ROQm3l",
        "outputId": "878dbcf5-676d-4f35-fc52-a89aebb8ee59"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 3, 3, 20, 17, 16, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model that contains char embedding, RNN, and projection layer\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "  def __init__(self, vocab_size:int, hidden_size=64):\n",
        "    super().__init__()\n",
        "    self.emb_layer = nn.Embedding(vocab_size, embedding_dim=hidden_size)\n",
        "    self.rnn = MyRNN(hidden_size, hidden_size)\n",
        "    self.proj_layer = nn.Linear(hidden_size, vocab_size) #\n",
        "\n",
        "  def forward(self, x):\n",
        "    # convert token indices to token vectors\n",
        "    embeddings = self.emb_layer(x)\n",
        "    hidden_states = self.rnn.run_sequence(embeddings)\n",
        "    logits = self.proj_layer(hidden_states)\n",
        "    probs = logits.softmax(dim=-1)\n",
        "\n",
        "    return probs\n",
        "\n",
        "model = LanguageModel(len(dataset.tokenizer), hidden_size=64)\n",
        "probs = model(input)\n",
        "loss = get_nll_loss(probs, target)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "fYz7dev-Rc1n"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "model = LanguageModel(len(dataset.tokenizer), hidden_size=64)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "loss_records = []\n",
        "\n",
        "for i in tqdm(range(len(dataset))):\n",
        "  input, target = dataset[i]\n",
        "  probs = model(input)\n",
        "  loss = get_nll_loss(probs, target)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  loss_records.append(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ca671949ee8c49ab9daeca8fa40fa1a7",
            "4ed00e9d699c414988a106b954a339d4",
            "6a8812ae67594b13bc6658360494d1f6",
            "193666baae04469a9d414f454e4897d2",
            "f90c7ea95b1b46a98e3bedf6dfa2d6fa",
            "4e39237ce5964f67a166e528ef217891",
            "027ad1c9304a4efab90a680fe0f84ab3",
            "5380d6c20d03476b898e29f55b13ba67",
            "22951171b66c464e883a842f26a3553f",
            "7423a43c76cd4f1584ba8b3c758b0874",
            "8796f334fae14d5b95599e3175e7bc11"
          ]
        },
        "id": "5S45RirkUj8W",
        "outputId": "5ee95d55-6fc5-4b5a-af98-fdc8f9a5c82c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/133650 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca671949ee8c49ab9daeca8fa40fa1a7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a new name with the model\n",
        "\n",
        "# torch.manual_seed(1)\n",
        "\n",
        "output_tokens = []\n",
        "previously_generated_token = torch.LongTensor([0]) # 'start/end' token idx is 0 in our vocab\n",
        "previous_hidden = torch.zeros(model.rnn.hidden_size)\n",
        "\n",
        "for i in range(100):\n",
        "  char_emb = model.emb_layer(previously_generated_token)\n",
        "  hidden = model.rnn.run_one_step(char_emb, previous_hidden)\n",
        "  previous_hidden = hidden\n",
        "  logit = model.proj_layer(hidden)\n",
        "  prob = logit.softmax(dim=-1)\n",
        "\n",
        "  # we have to sample one single token from the probability distribution\n",
        "  next_token = torch.multinomial(prob, num_samples=1)[0]\n",
        "  if next_token == 0: # start/end token\n",
        "    break\n",
        "  output_tokens.append(next_token.item())\n",
        "  previously_generated_token = next_token\n",
        "\n",
        "generated_name = dataset.tokenizer.decode(output_tokens)\n",
        "generated_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mr_MBu4YVX25",
        "outputId": "16b9ed97-565e-4c74-f140-175c8b7e7ec5"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cessaree'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca671949ee8c49ab9daeca8fa40fa1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ed00e9d699c414988a106b954a339d4",
              "IPY_MODEL_6a8812ae67594b13bc6658360494d1f6",
              "IPY_MODEL_193666baae04469a9d414f454e4897d2"
            ],
            "layout": "IPY_MODEL_f90c7ea95b1b46a98e3bedf6dfa2d6fa"
          }
        },
        "4ed00e9d699c414988a106b954a339d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e39237ce5964f67a166e528ef217891",
            "placeholder": "​",
            "style": "IPY_MODEL_027ad1c9304a4efab90a680fe0f84ab3",
            "value": "100%"
          }
        },
        "6a8812ae67594b13bc6658360494d1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5380d6c20d03476b898e29f55b13ba67",
            "max": 133650,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22951171b66c464e883a842f26a3553f",
            "value": 133650
          }
        },
        "193666baae04469a9d414f454e4897d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7423a43c76cd4f1584ba8b3c758b0874",
            "placeholder": "​",
            "style": "IPY_MODEL_8796f334fae14d5b95599e3175e7bc11",
            "value": " 133650/133650 [07:50&lt;00:00, 327.47it/s]"
          }
        },
        "f90c7ea95b1b46a98e3bedf6dfa2d6fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e39237ce5964f67a166e528ef217891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "027ad1c9304a4efab90a680fe0f84ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5380d6c20d03476b898e29f55b13ba67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22951171b66c464e883a842f26a3553f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7423a43c76cd4f1584ba8b3c758b0874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8796f334fae14d5b95599e3175e7bc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}